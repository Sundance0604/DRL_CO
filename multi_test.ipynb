{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带掩码的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'multiagent.MultiAgentAC'>\n",
      "第0次训练\n",
      "未加强化学习利润为255092.0,47次未求解\n",
      "第1次训练\n",
      "执行时间: 2.7156317234039307 秒,5次未求解，当前强化学习值为924195.0,利润为924195.0\n",
      "第2次训练\n",
      "执行时间: 4.827649116516113 秒,0次未求解，当前强化学习值为995869.0,利润为995869.0\n",
      "第3次训练\n",
      "执行时间: 5.959773778915405 秒,50次未求解，当前强化学习值为212754.0,利润为212754.0\n",
      "第4次训练\n",
      "执行时间: 8.039934635162354 秒,0次未求解，当前强化学习值为1005862.0,利润为1005862.0\n",
      "第5次训练\n",
      "执行时间: 9.250344038009644 秒,40次未求解，当前强化学习值为373270.0,利润为373270.0\n",
      "第6次训练\n",
      "执行时间: 10.60444188117981 秒,40次未求解，当前强化学习值为372921.0,利润为372921.0\n",
      "第7次训练\n",
      "执行时间: 12.48438310623169 秒,22次未求解，当前强化学习值为658220.0,利润为658220.0\n",
      "第8次训练\n",
      "执行时间: 13.951624155044556 秒,42次未求解，当前强化学习值为339078.0,利润为339078.0\n",
      "第9次训练\n",
      "执行时间: 16.532237768173218 秒,0次未求解，当前强化学习值为1013511.0,利润为1013511.0\n",
      "第10次训练\n",
      "执行时间: 18.84442162513733 秒,0次未求解，当前强化学习值为1013966.0,利润为1013966.0\n",
      "第11次训练\n",
      "执行时间: 20.112462282180786 秒,48次未求解，当前强化学习值为244140.0,利润为244140.0\n",
      "第12次训练\n",
      "执行时间: 21.999542474746704 秒,23次未求解，当前强化学习值为648328.0,利润为648328.0\n",
      "第13次训练\n",
      "执行时间: 24.64748239517212 秒,0次未求解，当前强化学习值为1002664.0,利润为1002664.0\n",
      "第14次训练\n",
      "执行时间: 27.386648416519165 秒,0次未求解，当前强化学习值为995092.0,利润为995092.0\n",
      "第15次训练\n",
      "执行时间: 29.872071266174316 秒,0次未求解，当前强化学习值为1000870.0,利润为1000870.0\n",
      "第16次训练\n",
      "执行时间: 32.61223602294922 秒,4次未求解，当前强化学习值为937916.0,利润为937916.0\n",
      "第17次训练\n",
      "执行时间: 34.36998963356018 秒,23次未求解，当前强化学习值为650578.0,利润为650578.0\n",
      "第18次训练\n",
      "执行时间: 35.26008152961731 秒,62次未求解，当前强化学习值为20652.0,利润为20652.0\n",
      "第19次训练\n",
      "执行时间: 36.25033164024353 秒,52次未求解，当前强化学习值为181155.0,利润为181155.0\n",
      "第20次训练\n",
      "执行时间: 37.70459342002869 秒,28次未求解，当前强化学习值为576778.0,利润为576778.0\n",
      "第21次训练\n",
      "执行时间: 39.22970509529114 秒,26次未求解，当前强化学习值为607845.0,利润为607845.0\n",
      "第22次训练\n",
      "执行时间: 41.12956523895264 秒,0次未求解，当前强化学习值为994622.0,利润为994622.0\n",
      "第23次训练\n",
      "执行时间: 42.78958344459534 秒,16次未求解，当前强化学习值为750799.0,利润为750799.0\n",
      "第24次训练\n",
      "执行时间: 43.66966772079468 秒,62次未求解，当前强化学习值为20652.0,利润为20652.0\n",
      "第25次训练\n",
      "执行时间: 44.59465432167053 秒,62次未求解，当前强化学习值为20653.0,利润为20653.0\n",
      "第26次训练\n",
      "执行时间: 46.481502056121826 秒,0次未求解，当前强化学习值为999367.0,利润为999367.0\n",
      "第27次训练\n",
      "执行时间: 48.5408353805542 秒,1次未求解，当前强化学习值为989972.0,利润为989972.0\n",
      "第28次训练\n",
      "执行时间: 49.81813597679138 秒,39次未求解，当前强化学习值为384901.0,利润为384901.0\n",
      "第29次训练\n",
      "执行时间: 51.57948350906372 秒,0次未求解，当前强化学习值为1002447.0,利润为1002447.0\n",
      "第30次训练\n",
      "执行时间: 52.84939360618591 秒,35次未求解，当前强化学习值为451551.0,利润为451551.0\n",
      "第31次训练\n",
      "执行时间: 54.50469160079956 秒,17次未求解，当前强化学习值为723708.0,利润为723708.0\n",
      "第32次训练\n",
      "执行时间: 55.94101595878601 秒,27次未求解，当前强化学习值为593657.0,利润为593657.0\n",
      "第33次训练\n",
      "执行时间: 57.572705030441284 秒,25次未求解，当前强化学习值为620033.0,利润为620033.0\n",
      "第34次训练\n",
      "执行时间: 59.529603481292725 秒,0次未求解，当前强化学习值为1004455.0,利润为1004455.0\n",
      "第35次训练\n",
      "执行时间: 61.32196092605591 秒,13次未求解，当前强化学习值为803266.0,利润为803266.0\n",
      "第36次训练\n",
      "执行时间: 63.10412955284119 秒,13次未求解，当前强化学习值为803663.0,利润为803663.0\n",
      "第37次训练\n",
      "执行时间: 65.34956622123718 秒,0次未求解，当前强化学习值为990634.0,利润为990634.0\n",
      "第38次训练\n",
      "执行时间: 66.83950114250183 秒,27次未求解，当前强化学习值为588448.0,利润为588448.0\n",
      "第39次训练\n",
      "执行时间: 68.3595781326294 秒,29次未求解，当前强化学习值为551647.0,利润为551647.0\n",
      "第40次训练\n",
      "执行时间: 69.82270693778992 秒,30次未求解，当前强化学习值为532808.0,利润为532808.0\n",
      "第41次训练\n",
      "执行时间: 71.29663157463074 秒,22次未求解，当前强化学习值为663502.0,利润为663502.0\n",
      "第42次训练\n",
      "执行时间: 73.59033942222595 秒,0次未求解，当前强化学习值为999295.0,利润为999295.0\n",
      "第43次训练\n",
      "执行时间: 75.60334062576294 秒,0次未求解，当前强化学习值为995353.0,利润为995353.0\n",
      "第44次训练\n",
      "执行时间: 76.81931853294373 秒,39次未求解，当前强化学习值为377840.0,利润为377840.0\n",
      "第45次训练\n",
      "执行时间: 77.8714952468872 秒,57次未求解，当前强化学习值为95009.0,利润为95009.0\n",
      "第46次训练\n",
      "执行时间: 79.05227780342102 秒,39次未求解，当前强化学习值为375675.0,利润为375675.0\n",
      "第47次训练\n",
      "执行时间: 80.99940085411072 秒,13次未求解，当前强化学习值为807517.0,利润为807517.0\n",
      "第48次训练\n",
      "执行时间: 82.26968169212341 秒,35次未求解，当前强化学习值为448994.0,利润为448994.0\n",
      "第49次训练\n",
      "执行时间: 83.71968722343445 秒,18次未求解，当前强化学习值为727538.0,利润为727538.0\n",
      "第50次训练\n",
      "执行时间: 85.38962364196777 秒,17次未求解，当前强化学习值为733775.0,利润为733775.0\n",
      "第51次训练\n",
      "执行时间: 87.40958952903748 秒,0次未求解，当前强化学习值为1001736.0,利润为1001736.0\n",
      "第52次训练\n",
      "执行时间: 89.32927370071411 秒,0次未求解，当前强化学习值为993949.0,利润为993949.0\n",
      "第53次训练\n",
      "执行时间: 91.2262589931488 秒,0次未求解，当前强化学习值为988009.0,利润为988009.0\n",
      "第54次训练\n",
      "执行时间: 92.25948119163513 秒,52次未求解，当前强化学习值为183203.0,利润为183203.0\n",
      "第55次训练\n",
      "执行时间: 94.41800665855408 秒,0次未求解，当前强化学习值为1004013.0,利润为1004013.0\n",
      "第56次训练\n",
      "执行时间: 95.93929147720337 秒,30次未求解，当前强化学习值为540850.0,利润为540850.0\n",
      "第57次训练\n",
      "执行时间: 97.8629686832428 秒,0次未求解，当前强化学习值为1003059.0,利润为1003059.0\n",
      "第58次训练\n",
      "执行时间: 100.0322494506836 秒,5次未求解，当前强化学习值为916155.0,利润为916155.0\n",
      "第59次训练\n",
      "执行时间: 102.05539512634277 秒,0次未求解，当前强化学习值为989876.0,利润为989876.0\n",
      "第60次训练\n",
      "执行时间: 103.26516842842102 秒,45次未求解，当前强化学习值为288841.0,利润为288841.0\n",
      "第61次训练\n",
      "执行时间: 105.41487646102905 秒,0次未求解，当前强化学习值为1013759.0,利润为1013759.0\n",
      "第62次训练\n",
      "执行时间: 107.03957223892212 秒,12次未求解，当前强化学习值为813098.0,利润为813098.0\n",
      "第63次训练\n",
      "执行时间: 108.67429661750793 秒,18次未求解，当前强化学习值为722252.0,利润为722252.0\n",
      "第64次训练\n",
      "执行时间: 110.31928277015686 秒,21次未求解，当前强化学习值为674426.0,利润为674426.0\n",
      "第65次训练\n",
      "执行时间: 111.89912414550781 秒,23次未求解，当前强化学习值为642901.0,利润为642901.0\n",
      "第66次训练\n",
      "执行时间: 113.94742894172668 秒,0次未求解，当前强化学习值为1004773.0,利润为1004773.0\n",
      "第67次训练\n",
      "执行时间: 115.18918490409851 秒,44次未求解，当前强化学习值为291410.0,利润为291410.0\n",
      "第68次训练\n",
      "执行时间: 116.331369638443 秒,47次未求解，当前强化学习值为259297.0,利润为259297.0\n",
      "第69次训练\n",
      "执行时间: 118.53416991233826 秒,0次未求解，当前强化学习值为1009137.0,利润为1009137.0\n",
      "第70次训练\n",
      "执行时间: 120.44952893257141 秒,0次未求解，当前强化学习值为994367.0,利润为994367.0\n",
      "第71次训练\n",
      "执行时间: 121.68931221961975 秒,39次未求解，当前强化学习值为385151.0,利润为385151.0\n",
      "第72次训练\n",
      "执行时间: 123.72951817512512 秒,20次未求解，当前强化学习值为682897.0,利润为682897.0\n",
      "第73次训练\n",
      "执行时间: 125.48933553695679 秒,17次未求解，当前强化学习值为729903.0,利润为729903.0\n",
      "第74次训练\n",
      "执行时间: 127.02950358390808 秒,22次未求解，当前强化学习值为661127.0,利润为661127.0\n",
      "第75次训练\n",
      "执行时间: 128.1393482685089 秒,47次未求解，当前强化学习值为255581.0,利润为255581.0\n",
      "第76次训练\n",
      "执行时间: 129.31018376350403 秒,43次未求解，当前强化学习值为322612.0,利润为322612.0\n",
      "第77次训练\n",
      "执行时间: 130.84927201271057 秒,22次未求解，当前强化学习值为666885.0,利润为666885.0\n",
      "第78次训练\n",
      "执行时间: 132.6122658252716 秒,10次未求解，当前强化学习值为839512.0,利润为839512.0\n",
      "第79次训练\n",
      "执行时间: 133.9157519340515 秒,40次未求解，当前强化学习值为371092.0,利润为371092.0\n",
      "第80次训练\n",
      "执行时间: 135.1643967628479 秒,39次未求解，当前强化学习值为390836.0,利润为390836.0\n",
      "第81次训练\n",
      "执行时间: 136.75894689559937 秒,23次未求解，当前强化学习值为648808.0,利润为648808.0\n",
      "第82次训练\n",
      "执行时间: 138.89415311813354 秒,0次未求解，当前强化学习值为997180.0,利润为997180.0\n",
      "第83次训练\n",
      "执行时间: 140.6489646434784 秒,0次未求解，当前强化学习值为1013686.0,利润为1013686.0\n",
      "第84次训练\n",
      "执行时间: 142.15967917442322 秒,23次未求解，当前强化学习值为642853.0,利润为642853.0\n",
      "第85次训练\n",
      "执行时间: 144.13332891464233 秒,0次未求解，当前强化学习值为1003708.0,利润为1003708.0\n",
      "第86次训练\n",
      "执行时间: 145.6291983127594 秒,29次未求解，当前强化学习值为552203.0,利润为552203.0\n",
      "第87次训练\n",
      "执行时间: 146.79894089698792 秒,42次未求解，当前强化学习值为333884.0,利润为333884.0\n",
      "第88次训练\n",
      "执行时间: 147.73434925079346 秒,62次未求解，当前强化学习值为20652.0,利润为20652.0\n",
      "第89次训练\n",
      "执行时间: 149.70108604431152 秒,0次未求解，当前强化学习值为1005655.0,利润为1005655.0\n",
      "第90次训练\n",
      "执行时间: 151.11561679840088 秒,33次未求解，当前强化学习值为488367.0,利润为488367.0\n",
      "第91次训练\n",
      "执行时间: 152.53967547416687 秒,36次未求解，当前强化学习值为435847.0,利润为435847.0\n",
      "第92次训练\n",
      "执行时间: 153.87941360473633 秒,36次未求解，当前强化学习值为435384.0,利润为435384.0\n",
      "第93次训练\n",
      "执行时间: 154.98408031463623 秒,50次未求解，当前强化学习值为212427.0,利润为212427.0\n",
      "第94次训练\n",
      "执行时间: 157.17445826530457 秒,0次未求解，当前强化学习值为995903.0,利润为995903.0\n",
      "第95次训练\n",
      "执行时间: 158.25545048713684 秒,57次未求解，当前强化学习值为97082.0,利润为97082.0\n",
      "第96次训练\n",
      "执行时间: 160.22227907180786 秒,0次未求解，当前强化学习值为992859.0,利润为992859.0\n",
      "第97次训练\n",
      "执行时间: 161.75648951530457 秒,27次未求解，当前强化学习值为583789.0,利润为583789.0\n",
      "第98次训练\n",
      "执行时间: 164.31296062469482 秒,0次未求解，当前强化学习值为998378.0,利润为998378.0\n",
      "第99次训练\n",
      "执行时间: 166.8960943222046 秒,0次未求解，当前强化学习值为1005890.0,利润为1005890.0\n",
      "第100次训练\n",
      "最优模型为9\n",
      "执行时间: 168.10928630828857 秒,53次未求解，当前强化学习值为163021.0,利润为163021.0\n",
      "第101次训练\n",
      "最优模型为9\n",
      "执行时间: 170.77048754692078 秒,0次未求解，当前强化学习值为997697.0,利润为997697.0\n",
      "第102次训练\n",
      "最优模型为9\n",
      "执行时间: 173.1802623271942 秒,2次未求解，当前强化学习值为985450.0,利润为985450.0\n",
      "第103次训练\n",
      "最优模型为9\n",
      "执行时间: 174.78411436080933 秒,43次未求解，当前强化学习值为321920.0,利润为321920.0\n",
      "第104次训练\n",
      "最优模型为9\n",
      "执行时间: 176.37675786018372 秒,57次未求解，当前强化学习值为98651.0,利润为98651.0\n",
      "第105次训练\n",
      "最优模型为9\n",
      "执行时间: 179.37221884727478 秒,0次未求解，当前强化学习值为995447.0,利润为995447.0\n",
      "第106次训练\n",
      "最优模型为9\n",
      "执行时间: 180.98471474647522 秒,36次未求解，当前强化学习值为439350.0,利润为439350.0\n",
      "第107次训练\n",
      "最优模型为9\n",
      "执行时间: 183.11464595794678 秒,23次未求解，当前强化学习值为652377.0,利润为652377.0\n",
      "第108次训练\n",
      "最优模型为9\n",
      "执行时间: 186.0394537448883 秒,0次未求解，当前强化学习值为1000939.0,利润为1000939.0\n",
      "第109次训练\n",
      "最优模型为9\n",
      "执行时间: 188.6346559524536 秒,0次未求解，当前强化学习值为1013869.0,利润为1013869.0\n",
      "第110次训练\n",
      "最优模型为9\n",
      "执行时间: 190.99608993530273 秒,17次未求解，当前强化学习值为735073.0,利润为735073.0\n",
      "第111次训练\n",
      "最优模型为9\n",
      "执行时间: 192.32997798919678 秒,57次未求解，当前强化学习值为98644.0,利润为98644.0\n",
      "第112次训练\n",
      "最优模型为9\n",
      "执行时间: 194.45800375938416 秒,18次未求解，当前强化学习值为727874.0,利润为727874.0\n",
      "第113次训练\n",
      "最优模型为9\n",
      "执行时间: 197.18726778030396 秒,0次未求解，当前强化学习值为992030.0,利润为992030.0\n",
      "第114次训练\n",
      "最优模型为9\n",
      "执行时间: 199.79093718528748 秒,5次未求解，当前强化学习值为931984.0,利润为931984.0\n",
      "第115次训练\n",
      "最优模型为9\n",
      "执行时间: 202.23249197006226 秒,0次未求解，当前强化学习值为1012477.0,利润为1012477.0\n",
      "第116次训练\n",
      "最优模型为9\n",
      "执行时间: 204.84146690368652 秒,0次未求解，当前强化学习值为1004444.0,利润为1004444.0\n",
      "第117次训练\n",
      "最优模型为9\n",
      "执行时间: 206.0166187286377 秒,52次未求解，当前强化学习值为178647.0,利润为178647.0\n",
      "第118次训练\n",
      "最优模型为9\n",
      "执行时间: 208.68311047554016 秒,0次未求解，当前强化学习值为997712.0,利润为997712.0\n",
      "第119次训练\n",
      "最优模型为9\n",
      "执行时间: 210.10138034820557 秒,48次未求解，当前强化学习值为237573.0,利润为237573.0\n",
      "第120次训练\n",
      "最优模型为9\n",
      "执行时间: 211.4917709827423 秒,48次未求解，当前强化学习值为238658.0,利润为238658.0\n",
      "第121次训练\n",
      "最优模型为9\n",
      "执行时间: 213.7805564403534 秒,17次未求解，当前强化学习值为729654.0,利润为729654.0\n",
      "第122次训练\n",
      "最优模型为9\n",
      "执行时间: 215.85501551628113 秒,18次未求解，当前强化学习值为719651.0,利润为719651.0\n",
      "第123次训练\n",
      "最优模型为9\n",
      "执行时间: 217.1979923248291 秒,47次未求解，当前强化学习值为257417.0,利润为257417.0\n",
      "第124次训练\n",
      "最优模型为9\n",
      "执行时间: 218.37504959106445 秒,54次未求解，当前强化学习值为145261.0,利润为145261.0\n",
      "第125次训练\n",
      "最优模型为9\n",
      "执行时间: 220.22294354438782 秒,23次未求解，当前强化学习值为652313.0,利润为652313.0\n",
      "第126次训练\n",
      "最优模型为9\n",
      "执行时间: 222.84754705429077 秒,0次未求解，当前强化学习值为1005509.0,利润为1005509.0\n",
      "第127次训练\n",
      "最优模型为9\n",
      "执行时间: 224.52287459373474 秒,39次未求解，当前强化学习值为377724.0,利润为377724.0\n",
      "第128次训练\n",
      "最优模型为9\n",
      "执行时间: 226.44033360481262 秒,22次未求解，当前强化学习值为666478.0,利润为666478.0\n",
      "第129次训练\n",
      "最优模型为9\n",
      "执行时间: 228.9796380996704 秒,0次未求解，当前强化学习值为1002799.0,利润为1002799.0\n",
      "第130次训练\n",
      "最优模型为9\n",
      "执行时间: 231.40879726409912 秒,0次未求解，当前强化学习值为1002471.0,利润为1002471.0\n",
      "第131次训练\n",
      "最优模型为9\n",
      "执行时间: 233.1132369041443 秒,36次未求解，当前强化学习值为436749.0,利润为436749.0\n",
      "第132次训练\n",
      "最优模型为9\n",
      "执行时间: 235.21049404144287 秒,14次未求解，当前强化学习值为786590.0,利润为786590.0\n",
      "第133次训练\n",
      "最优模型为9\n",
      "执行时间: 236.29892015457153 秒,57次未求解，当前强化学习值为98630.0,利润为98630.0\n",
      "第134次训练\n",
      "最优模型为9\n",
      "执行时间: 237.77168202400208 秒,43次未求解，当前强化学习值为317869.0,利润为317869.0\n",
      "第135次训练\n",
      "最优模型为9\n",
      "执行时间: 238.83784437179565 秒,62次未求解，当前强化学习值为18473.0,利润为18473.0\n",
      "第136次训练\n",
      "最优模型为9\n",
      "执行时间: 240.657390832901 秒,25次未求解，当前强化学习值为619946.0,利润为619946.0\n",
      "第137次训练\n",
      "最优模型为9\n",
      "执行时间: 242.98722195625305 秒,0次未求解，当前强化学习值为1006619.0,利润为1006619.0\n",
      "第138次训练\n",
      "最优模型为9\n",
      "执行时间: 244.89516520500183 秒,27次未求解，当前强化学习值为590504.0,利润为590504.0\n",
      "第139次训练\n",
      "最优模型为9\n",
      "执行时间: 247.19590663909912 秒,0次未求解，当前强化学习值为1003616.0,利润为1003616.0\n",
      "第140次训练\n",
      "最优模型为9\n",
      "执行时间: 248.39560866355896 秒,54次未求解，当前强化学习值为145261.0,利润为145261.0\n",
      "第141次训练\n",
      "最优模型为9\n",
      "执行时间: 250.16016030311584 秒,25次未求解，当前强化学习值为615308.0,利润为615308.0\n",
      "第142次训练\n",
      "最优模型为9\n",
      "执行时间: 252.16599369049072 秒,21次未求解，当前强化学习值为673074.0,利润为673074.0\n",
      "第143次训练\n",
      "最优模型为9\n",
      "执行时间: 254.81545281410217 秒,0次未求解，当前强化学习值为997842.0,利润为997842.0\n",
      "第144次训练\n",
      "最优模型为9\n",
      "执行时间: 256.4536395072937 秒,36次未求解，当前强化学习值为425002.0,利润为425002.0\n",
      "第145次训练\n",
      "最优模型为9\n",
      "执行时间: 258.2169785499573 秒,27次未求解，当前强化学习值为586463.0,利润为586463.0\n",
      "第146次训练\n",
      "最优模型为9\n",
      "执行时间: 259.66759037971497 秒,47次未求解，当前强化学习值为259142.0,利润为259142.0\n",
      "第147次训练\n",
      "最优模型为9\n",
      "执行时间: 262.1596302986145 秒,0次未求解，当前强化学习值为1006123.0,利润为1006123.0\n",
      "第148次训练\n",
      "最优模型为9\n",
      "执行时间: 263.4788064956665 秒,43次未求解，当前强化学习值为320211.0,利润为320211.0\n",
      "第149次训练\n",
      "最优模型为9\n",
      "执行时间: 264.98992228507996 秒,40次未求解，当前强化学习值为372800.0,利润为372800.0\n",
      "第150次训练\n",
      "最优模型为9\n",
      "执行时间: 267.477658033371 秒,0次未求解，当前强化学习值为995786.0,利润为995786.0\n",
      "第151次训练\n",
      "最优模型为9\n",
      "执行时间: 269.6961998939514 秒,17次未求解，当前强化学习值为732666.0,利润为732666.0\n",
      "第152次训练\n",
      "最优模型为9\n",
      "执行时间: 272.6239187717438 秒,0次未求解，当前强化学习值为1000159.9999057571,利润为1000159.9999057571\n",
      "第153次训练\n",
      "最优模型为9\n",
      "执行时间: 275.34589648246765 秒,0次未求解，当前强化学习值为1018282.9990379617,利润为1018282.9990379617\n",
      "第154次训练\n",
      "最优模型为152\n",
      "执行时间: 276.7786509990692 秒,47次未求解，当前强化学习值为254778.0,利润为254778.0\n",
      "第155次训练\n",
      "最优模型为152\n",
      "执行时间: 279.38525390625 秒,0次未求解，当前强化学习值为1000732.0,利润为1000732.0\n",
      "第156次训练\n",
      "最优模型为152\n",
      "执行时间: 281.9356997013092 秒,0次未求解，当前强化学习值为996592.0,利润为996592.0\n",
      "第157次训练\n",
      "最优模型为152\n",
      "执行时间: 282.9854292869568 秒,62次未求解，当前强化学习值为20653.0,利润为20653.0\n",
      "第158次训练\n",
      "最优模型为152\n",
      "执行时间: 285.53410840034485 秒,0次未求解，当前强化学习值为1002536.0,利润为1002536.0\n",
      "第159次训练\n",
      "最优模型为152\n",
      "执行时间: 287.96471881866455 秒,0次未求解，当前强化学习值为1010783.0,利润为1010783.0\n",
      "第160次训练\n",
      "最优模型为152\n",
      "执行时间: 290.4265341758728 秒,0次未求解，当前强化学习值为1012467.0,利润为1012467.0\n",
      "第161次训练\n",
      "最优模型为152\n",
      "执行时间: 291.78851866722107 秒,40次未求解，当前强化学习值为370175.0,利润为370175.0\n",
      "第162次训练\n",
      "最优模型为152\n",
      "执行时间: 294.4685070514679 秒,10次未求解，当前强化学习值为850150.0,利润为850150.0\n",
      "第163次训练\n",
      "最优模型为152\n",
      "执行时间: 295.48869156837463 秒,62次未求解，当前强化学习值为20652.0,利润为20652.0\n",
      "第164次训练\n",
      "最优模型为152\n",
      "执行时间: 297.3671066761017 秒,29次未求解，当前强化学习值为548452.0,利润为548452.0\n",
      "第165次训练\n",
      "最优模型为152\n",
      "执行时间: 298.6385278701782 秒,50次未求解，当前强化学习值为206652.0,利润为206652.0\n",
      "第166次训练\n",
      "最优模型为152\n",
      "执行时间: 301.2554290294647 秒,0次未求解，当前强化学习值为1008616.0,利润为1008616.0\n",
      "第167次训练\n",
      "最优模型为152\n",
      "执行时间: 302.8453743457794 秒,39次未求解，当前强化学习值为388729.0,利润为388729.0\n",
      "第168次训练\n",
      "最优模型为152\n",
      "执行时间: 305.1195909976959 秒,10次未求解，当前强化学习值为840939.0,利润为840939.0\n",
      "第169次训练\n",
      "最优模型为152\n",
      "执行时间: 306.0683946609497 秒,62次未求解，当前强化学习值为18473.0,利润为18473.0\n",
      "第170次训练\n",
      "最优模型为152\n",
      "执行时间: 308.8352255821228 秒,0次未求解，当前强化学习值为1002543.0,利润为1002543.0\n",
      "第171次训练\n",
      "最优模型为152\n",
      "执行时间: 311.1587245464325 秒,5次未求解，当前强化学习值为924127.0,利润为924127.0\n",
      "第172次训练\n",
      "最优模型为152\n",
      "执行时间: 313.9594039916992 秒,0次未求解，当前强化学习值为995358.0,利润为995358.0\n",
      "第173次训练\n",
      "最优模型为152\n",
      "执行时间: 315.88319277763367 秒,27次未求解，当前强化学习值为584401.0,利润为584401.0\n",
      "第174次训练\n",
      "最优模型为152\n",
      "执行时间: 318.6701843738556 秒,0次未求解，当前强化学习值为1007628.0,利润为1007628.0\n",
      "第175次训练\n",
      "最优模型为152\n",
      "执行时间: 320.2390401363373 秒,40次未求解，当前强化学习值为374645.0,利润为374645.0\n",
      "第176次训练\n",
      "最优模型为152\n",
      "执行时间: 322.32567167282104 秒,16次未求解，当前强化学习值为755151.0,利润为755151.0\n",
      "第177次训练\n",
      "最优模型为152\n",
      "执行时间: 324.7819232940674 秒,0次未求解，当前强化学习值为1004121.0,利润为1004121.0\n",
      "第178次训练\n",
      "最优模型为152\n",
      "执行时间: 326.378536939621 秒,40次未求解，当前强化学习值为370628.0,利润为370628.0\n",
      "第179次训练\n",
      "最优模型为152\n",
      "执行时间: 329.2449264526367 秒,0次未求解，当前强化学习值为1012223.0,利润为1012223.0\n",
      "第180次训练\n",
      "最优模型为152\n",
      "执行时间: 331.6983072757721 秒,0次未求解，当前强化学习值为1000643.0,利润为1000643.0\n",
      "第181次训练\n",
      "最优模型为152\n",
      "执行时间: 333.1167538166046 秒,44次未求解，当前强化学习值为297605.0,利润为297605.0\n",
      "第182次训练\n",
      "最优模型为152\n",
      "执行时间: 335.33840322494507 秒,6次未求解，当前强化学习值为918460.0,利润为918460.0\n",
      "第183次训练\n",
      "最优模型为152\n",
      "执行时间: 336.79831552505493 秒,42次未求解，当前强化学习值为330426.0,利润为330426.0\n",
      "第184次训练\n",
      "最优模型为152\n",
      "执行时间: 338.21509742736816 秒,44次未求解，当前强化学习值为297130.0,利润为297130.0\n",
      "第185次训练\n",
      "最优模型为152\n",
      "执行时间: 340.6504442691803 秒,0次未求解，当前强化学习值为1002400.0,利润为1002400.0\n",
      "第186次训练\n",
      "最优模型为152\n",
      "执行时间: 342.5585916042328 秒,24次未求解，当前强化学习值为636655.0,利润为636655.0\n",
      "第187次训练\n",
      "最优模型为152\n",
      "执行时间: 345.0730605125427 秒,17次未求解，当前强化学习值为724694.0,利润为724694.0\n",
      "第188次训练\n",
      "最优模型为152\n",
      "执行时间: 347.9183075428009 秒,0次未求解，当前强化学习值为1004330.0,利润为1004330.0\n",
      "第189次训练\n",
      "最优模型为152\n",
      "执行时间: 349.42813515663147 秒,40次未求解，当前强化学习值为366619.0,利润为366619.0\n",
      "第190次训练\n",
      "最优模型为152\n",
      "执行时间: 351.71828746795654 秒,7次未求解，当前强化学习值为888557.0,利润为888557.0\n",
      "第191次训练\n",
      "最优模型为152\n",
      "执行时间: 353.14439392089844 秒,43次未求解，当前强化学习值为320222.0,利润为320222.0\n",
      "第192次训练\n",
      "最优模型为152\n",
      "执行时间: 354.5880765914917 秒,44次未求解，当前强化学习值为298939.0,利润为298939.0\n",
      "第193次训练\n",
      "最优模型为152\n",
      "执行时间: 357.3608434200287 秒,0次未求解，当前强化学习值为998989.0,利润为998989.0\n",
      "第194次训练\n",
      "最优模型为152\n",
      "执行时间: 360.06997323036194 秒,0次未求解，当前强化学习值为1006043.0,利润为1006043.0\n",
      "第195次训练\n",
      "最优模型为152\n",
      "执行时间: 362.4477307796478 秒,0次未求解，当前强化学习值为1000126.0,利润为1000126.0\n",
      "第196次训练\n",
      "最优模型为152\n",
      "执行时间: 363.84401178359985 秒,43次未求解，当前强化学习值为314474.0,利润为314474.0\n",
      "第197次训练\n",
      "最优模型为152\n",
      "执行时间: 365.70584630966187 秒,40次未求解，当前强化学习值为368253.0,利润为368253.0\n",
      "第198次训练\n",
      "最优模型为152\n",
      "执行时间: 367.1668748855591 秒,45次未求解，当前强化学习值为282501.0,利润为282501.0\n",
      "第199次训练\n",
      "最优模型为152\n",
      "执行时间: 369.4579746723175 秒,0次未求解，当前强化学习值为1009391.0,利润为1009391.0\n",
      "第200次训练\n",
      "最优模型为152\n",
      "执行时间: 371.8585340976715 秒,0次未求解，当前强化学习值为1008695.0,利润为1008695.0\n",
      "第201次训练\n",
      "最优模型为152\n",
      "执行时间: 374.3730034828186 秒,0次未求解，当前强化学习值为1004734.0,利润为1004734.0\n",
      "第202次训练\n",
      "最优模型为152\n",
      "执行时间: 375.898334980011 秒,49次未求解，当前强化学习值为225020.0,利润为225020.0\n",
      "第203次训练\n",
      "最优模型为152\n",
      "执行时间: 377.37821531295776 秒,62次未求解，当前强化学习值为20653.0,利润为20653.0\n",
      "第204次训练\n",
      "最优模型为152\n",
      "执行时间: 380.1179885864258 秒,0次未求解，当前强化学习值为1007662.0,利润为1007662.0\n",
      "第205次训练\n",
      "最优模型为152\n",
      "执行时间: 381.9495544433594 秒,26次未求解，当前强化学习值为598884.0,利润为598884.0\n",
      "第206次训练\n",
      "最优模型为152\n",
      "执行时间: 383.5782651901245 秒,36次未求解，当前强化学习值为427583.0,利润为427583.0\n",
      "第207次训练\n",
      "最优模型为152\n",
      "执行时间: 386.16804456710815 秒,3次未求解，当前强化学习值为964191.0,利润为964191.0\n",
      "第208次训练\n",
      "最优模型为152\n",
      "执行时间: 387.388055562973 秒,53次未求解，当前强化学习值为165895.0,利润为165895.0\n",
      "第209次训练\n",
      "最优模型为152\n",
      "执行时间: 389.9516792297363 秒,0次未求解，当前强化学习值为1004050.0,利润为1004050.0\n",
      "第210次训练\n",
      "最优模型为152\n",
      "执行时间: 391.31667041778564 秒,50次未求解，当前强化学习值为207845.0,利润为207845.0\n",
      "第211次训练\n",
      "最优模型为152\n",
      "执行时间: 392.7651982307434 秒,51次未求解，当前强化学习值为198076.0,利润为198076.0\n",
      "第212次训练\n",
      "最优模型为152\n",
      "执行时间: 395.4647936820984 秒,0次未求解，当前强化学习值为1004075.0,利润为1004075.0\n",
      "第213次训练\n",
      "最优模型为152\n",
      "执行时间: 397.9456286430359 秒,18次未求解，当前强化学习值为717944.0,利润为717944.0\n",
      "第214次训练\n",
      "最优模型为152\n",
      "执行时间: 399.32321190834045 秒,54次未求解，当前强化学习值为148093.0,利润为148093.0\n",
      "第215次训练\n",
      "最优模型为152\n",
      "执行时间: 402.3246774673462 秒,0次未求解，当前强化学习值为994367.0,利润为994367.0\n",
      "第216次训练\n",
      "最优模型为152\n",
      "执行时间: 404.2729880809784 秒,25次未求解，当前强化学习值为617804.0,利润为617804.0\n",
      "第217次训练\n",
      "最优模型为152\n",
      "执行时间: 406.26061153411865 秒,25次未求解，当前强化学习值为614736.0,利润为614736.0\n",
      "第218次训练\n",
      "最优模型为152\n",
      "执行时间: 408.8487901687622 秒,0次未求解，当前强化学习值为1002452.0,利润为1002452.0\n",
      "第219次训练\n",
      "最优模型为152\n",
      "执行时间: 411.24612498283386 秒,5次未求解，当前强化学习值为931473.0,利润为931473.0\n",
      "第220次训练\n",
      "最优模型为152\n",
      "执行时间: 413.0182273387909 秒,34次未求解，当前强化学习值为463472.0,利润为463472.0\n",
      "第221次训练\n",
      "最优模型为152\n",
      "执行时间: 414.052526473999 秒,61次未求解，当前强化学习值为33089.0,利润为33089.0\n",
      "第222次训练\n",
      "最优模型为152\n",
      "执行时间: 416.2465088367462 秒,18次未求解，当前强化学习值为728098.0,利润为728098.0\n",
      "第223次训练\n",
      "最优模型为152\n",
      "执行时间: 418.5807194709778 秒,0次未求解，当前强化学习值为999712.0,利润为999712.0\n",
      "第224次训练\n",
      "最优模型为152\n",
      "执行时间: 420.3855016231537 秒,25次未求解，当前强化学习值为619506.0,利润为619506.0\n",
      "第225次训练\n",
      "最优模型为152\n",
      "执行时间: 422.49649834632874 秒,17次未求解，当前强化学习值为736908.0,利润为736908.0\n",
      "第226次训练\n",
      "最优模型为152\n",
      "执行时间: 424.34352946281433 秒,23次未求解，当前强化学习值为648883.0,利润为648883.0\n",
      "第227次训练\n",
      "最优模型为152\n",
      "执行时间: 427.0462954044342 秒,0次未求解，当前强化学习值为992817.0,利润为992817.0\n",
      "第228次训练\n",
      "最优模型为152\n",
      "执行时间: 429.44927644729614 秒,9次未求解，当前强化学习值为858501.0,利润为858501.0\n",
      "第229次训练\n",
      "最优模型为152\n",
      "执行时间: 431.88928961753845 秒,0次未求解，当前强化学习值为993938.0,利润为993938.0\n",
      "第230次训练\n",
      "最优模型为152\n",
      "执行时间: 433.82210516929626 秒,26次未求解，当前强化学习值为600931.0,利润为600931.0\n",
      "第231次训练\n",
      "最优模型为152\n",
      "执行时间: 435.93329191207886 秒,17次未求解，当前强化学习值为739367.0,利润为739367.0\n",
      "第232次训练\n",
      "最优模型为152\n",
      "执行时间: 438.35189390182495 秒,0次未求解，当前强化学习值为999297.0,利润为999297.0\n",
      "第233次训练\n",
      "最优模型为152\n",
      "执行时间: 440.75466871261597 秒,0次未求解，当前强化学习值为1000916.0,利润为1000916.0\n",
      "第234次训练\n",
      "最优模型为152\n",
      "执行时间: 443.3964431285858 秒,5次未求解，当前强化学习值为918793.0,利润为918793.0\n",
      "第235次训练\n",
      "最优模型为152\n",
      "执行时间: 444.41364645957947 秒,61次未求解，当前强化学习值为33099.0,利润为33099.0\n",
      "第236次训练\n",
      "最优模型为152\n",
      "执行时间: 445.88911843299866 秒,47次未求解，当前强化学习值为243839.0,利润为243839.0\n",
      "第237次训练\n",
      "最优模型为152\n",
      "执行时间: 447.2955985069275 秒,45次未求解，当前强化学习值为285580.0,利润为285580.0\n",
      "第238次训练\n",
      "最优模型为152\n",
      "执行时间: 449.43229246139526 秒,17次未求解，当前强化学习值为731968.0,利润为731968.0\n",
      "第239次训练\n",
      "最优模型为152\n",
      "执行时间: 451.84675455093384 秒,0次未求解，当前强化学习值为1001252.0,利润为1001252.0\n",
      "第240次训练\n",
      "最优模型为152\n",
      "执行时间: 453.3286325931549 秒,39次未求解，当前强化学习值为386472.0,利润为386472.0\n",
      "第241次训练\n",
      "最优模型为152\n",
      "执行时间: 454.90663838386536 秒,39次未求解，当前强化学习值为387720.0,利润为387720.0\n",
      "第242次训练\n",
      "最优模型为152\n",
      "执行时间: 456.98076486587524 秒,18次未求解，当前强化学习值为725105.0,利润为725105.0\n",
      "第243次训练\n",
      "最优模型为152\n",
      "执行时间: 459.4410388469696 秒,0次未求解，当前强化学习值为1004312.0,利润为1004312.0\n",
      "第244次训练\n",
      "最优模型为152\n",
      "执行时间: 460.423939704895 秒,62次未求解，当前强化学习值为18473.0,利润为18473.0\n",
      "第245次训练\n",
      "最优模型为152\n",
      "执行时间: 463.15005230903625 秒,0次未求解，当前强化学习值为1002373.0,利润为1002373.0\n",
      "第246次训练\n",
      "最优模型为152\n",
      "执行时间: 465.0776538848877 秒,18次未求解，当前强化学习值为728310.0,利润为728310.0\n",
      "第247次训练\n",
      "最优模型为152\n",
      "执行时间: 466.4548180103302 秒,45次未求解，当前强化学习值为283573.0,利润为283573.0\n",
      "第248次训练\n",
      "最优模型为152\n",
      "执行时间: 467.99140524864197 秒,40次未求解，当前强化学习值为372511.0,利润为372511.0\n",
      "第249次训练\n",
      "最优模型为152\n",
      "执行时间: 469.47403502464294 秒,42次未求解，当前强化学习值为336232.0,利润为336232.0\n",
      "第250次训练\n",
      "最优模型为152\n",
      "执行时间: 471.35138154029846 秒,28次未求解，当前强化学习值为561791.0,利润为561791.0\n",
      "第251次训练\n",
      "最优模型为152\n",
      "执行时间: 472.6275837421417 秒,62次未求解，当前强化学习值为18473.0,利润为18473.0\n",
      "第252次训练\n",
      "最优模型为152\n",
      "执行时间: 475.0012707710266 秒,0次未求解，当前强化学习值为1000342.0,利润为1000342.0\n",
      "第253次训练\n",
      "最优模型为152\n",
      "执行时间: 476.80758810043335 秒,30次未求解，当前强化学习值为540698.0,利润为540698.0\n",
      "第254次训练\n",
      "最优模型为152\n",
      "执行时间: 479.3594105243683 秒,0次未求解，当前强化学习值为1001456.0,利润为1001456.0\n",
      "第255次训练\n",
      "最优模型为152\n",
      "执行时间: 481.9265933036804 秒,0次未求解，当前强化学习值为997428.0,利润为997428.0\n",
      "第256次训练\n",
      "最优模型为152\n",
      "执行时间: 484.20495986938477 秒,0次未求解，当前强化学习值为1004376.0,利润为1004376.0\n",
      "第257次训练\n",
      "最优模型为152\n",
      "执行时间: 485.3364005088806 秒,54次未求解，当前强化学习值为143272.0,利润为143272.0\n",
      "第258次训练\n",
      "最优模型为152\n",
      "执行时间: 487.55495858192444 秒,26次未求解，当前强化学习值为589125.0,利润为589125.0\n",
      "第259次训练\n",
      "最优模型为152\n",
      "执行时间: 489.7495050430298 秒,20次未求解，当前强化学习值为688960.0,利润为688960.0\n",
      "第260次训练\n",
      "最优模型为152\n",
      "执行时间: 492.4855589866638 秒,0次未求解，当前强化学习值为1004356.0,利润为1004356.0\n",
      "第261次训练\n",
      "最优模型为152\n",
      "执行时间: 494.99079966545105 秒,0次未求解，当前强化学习值为1005945.0,利润为1005945.0\n",
      "第262次训练\n",
      "最优模型为152\n",
      "执行时间: 497.3464331626892 秒,0次未求解，当前强化学习值为1004402.0,利润为1004402.0\n",
      "第263次训练\n",
      "最优模型为152\n",
      "执行时间: 499.28441286087036 秒,22次未求解，当前强化学习值为659824.0,利润为659824.0\n",
      "第264次训练\n",
      "最优模型为152\n",
      "执行时间: 501.5212616920471 秒,12次未求解，当前强化学习值为807976.0,利润为807976.0\n",
      "第265次训练\n",
      "最优模型为152\n",
      "执行时间: 503.7841765880585 秒,40次未求解，当前强化学习值为370694.0,利润为370694.0\n",
      "第266次训练\n",
      "最优模型为152\n",
      "执行时间: 506.30505323410034 秒,0次未求解，当前强化学习值为999046.0,利润为999046.0\n",
      "第267次训练\n",
      "最优模型为152\n",
      "执行时间: 508.14754986763 秒,29次未求解，当前强化学习值为551915.0,利润为551915.0\n",
      "第268次训练\n",
      "最优模型为152\n",
      "执行时间: 509.6105492115021 秒,39次未求解，当前强化学习值为380091.0,利润为380091.0\n",
      "第269次训练\n",
      "最优模型为152\n",
      "执行时间: 512.2174170017242 秒,0次未求解，当前强化学习值为1000765.0,利润为1000765.0\n",
      "第270次训练\n",
      "最优模型为152\n",
      "执行时间: 513.1779489517212 秒,62次未求解，当前强化学习值为18472.0,利润为18472.0\n",
      "第271次训练\n",
      "最优模型为152\n",
      "执行时间: 514.7156112194061 秒,43次未求解，当前强化学习值为323883.0,利润为323883.0\n",
      "第272次训练\n",
      "最优模型为152\n",
      "执行时间: 517.1790862083435 秒,0次未求解，当前强化学习值为998958.0,利润为998958.0\n",
      "第273次训练\n",
      "最优模型为152\n",
      "执行时间: 519.198921918869 秒,22次未求解，当前强化学习值为661214.0,利润为661214.0\n",
      "第274次训练\n",
      "最优模型为152\n",
      "执行时间: 521.5867800712585 秒,0次未求解，当前强化学习值为997883.0,利润为997883.0\n",
      "第275次训练\n",
      "最优模型为152\n",
      "执行时间: 525.4478857517242 秒,0次未求解，当前强化学习值为1003976.0,利润为1003976.0\n",
      "第276次训练\n",
      "最优模型为152\n",
      "执行时间: 527.133073091507 秒,41次未求解，当前强化学习值为362143.0,利润为362143.0\n",
      "第277次训练\n",
      "最优模型为152\n",
      "执行时间: 528.9375514984131 秒,36次未求解，当前强化学习值为441645.0,利润为441645.0\n",
      "第278次训练\n",
      "最优模型为152\n",
      "执行时间: 530.4362950325012 秒,43次未求解，当前强化学习值为324201.0,利润为324201.0\n",
      "第279次训练\n",
      "最优模型为152\n",
      "执行时间: 532.0446560382843 秒,48次未求解，当前强化学习值为238626.0,利润为238626.0\n",
      "第280次训练\n",
      "最优模型为152\n",
      "执行时间: 534.965204000473 秒,0次未求解，当前强化学习值为987068.0,利润为987068.0\n",
      "第281次训练\n",
      "最优模型为152\n",
      "执行时间: 536.5018434524536 秒,46次未求解，当前强化学习值为276690.0,利润为276690.0\n",
      "第282次训练\n",
      "最优模型为152\n",
      "执行时间: 538.6204342842102 秒,23次未求解，当前强化学习值为650602.0,利润为650602.0\n",
      "第283次训练\n",
      "最优模型为152\n",
      "执行时间: 539.952229976654 秒,50次未求解，当前强化学习值为214781.0,利润为214781.0\n",
      "第284次训练\n",
      "最优模型为152\n",
      "执行时间: 541.9472687244415 秒,12次未求解，当前强化学习值为824883.0,利润为824883.0\n",
      "第285次训练\n",
      "最优模型为152\n",
      "执行时间: 544.6130635738373 秒,0次未求解，当前强化学习值为994486.0,利润为994486.0\n",
      "第286次训练\n",
      "最优模型为152\n",
      "执行时间: 546.9210424423218 秒,9次未求解，当前强化学习值为875439.0,利润为875439.0\n",
      "第287次训练\n",
      "最优模型为152\n",
      "执行时间: 548.7774152755737 秒,28次未求解，当前强化学习值为566471.0,利润为566471.0\n",
      "第288次训练\n",
      "最优模型为152\n",
      "执行时间: 550.969907283783 秒,16次未求解，当前强化学习值为762196.0,利润为762196.0\n",
      "第289次训练\n",
      "最优模型为152\n",
      "执行时间: 553.2842354774475 秒,0次未求解，当前强化学习值为1015454.0,利润为1015454.0\n",
      "第290次训练\n",
      "最优模型为152\n",
      "执行时间: 556.0074753761292 秒,0次未求解，当前强化学习值为993398.0,利润为993398.0\n",
      "第291次训练\n",
      "最优模型为152\n",
      "执行时间: 558.4612483978271 秒,0次未求解，当前强化学习值为1002451.0,利润为1002451.0\n",
      "第292次训练\n",
      "最优模型为152\n",
      "执行时间: 560.9621391296387 秒,0次未求解，当前强化学习值为1000767.0,利润为1000767.0\n",
      "第293次训练\n",
      "最优模型为152\n",
      "执行时间: 563.6857032775879 秒,0次未求解，当前强化学习值为997707.0,利润为997707.0\n",
      "第294次训练\n",
      "最优模型为152\n",
      "执行时间: 565.3974249362946 秒,39次未求解，当前强化学习值为379314.0,利润为379314.0\n",
      "第295次训练\n",
      "最优模型为152\n",
      "执行时间: 566.8774106502533 秒,45次未求解，当前强化学习值为283253.0,利润为283253.0\n",
      "第296次训练\n",
      "最优模型为152\n",
      "执行时间: 569.6716051101685 秒,0次未求解，当前强化学习值为999464.0,利润为999464.0\n",
      "第297次训练\n",
      "最优模型为152\n",
      "执行时间: 570.927318572998 秒,50次未求解，当前强化学习值为202256.0,利润为202256.0\n",
      "第298次训练\n",
      "最优模型为152\n",
      "执行时间: 572.6651618480682 秒,50次未求解，当前强化学习值为210483.0,利润为210483.0\n",
      "第299次训练\n",
      "最优模型为152\n",
      "执行时间: 575.3575100898743 秒,0次未求解，当前强化学习值为1002386.0,利润为1002386.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from gurobipy import *\n",
    "from CITY_GRAPH import *\n",
    "from CITY_NODE import *\n",
    "from ORDER import *\n",
    "from VEHICLE import *\n",
    "from tool_func import *\n",
    "from Lower_Layer import *\n",
    "import SETTING\n",
    "import importlib\n",
    "import tool_func\n",
    "from update import *\n",
    "import os\n",
    "import time as tm\n",
    "import copy\n",
    "from my_env import *\n",
    "import torch\n",
    "import multiagent as magent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"这里是非强化学习部分\"\"\"\n",
    "# 初始化\n",
    "num_vehicle = 20\n",
    "num_order = 6\n",
    "num_city = 8\n",
    "TIME = 144  # \n",
    "CAPACITY = 7\n",
    "row = [10, 1, 3, 10]\n",
    "Vehicles = {}\n",
    "speed = 20 # 之前是20\n",
    "cancel_penalty = 300\n",
    "battery_consume = 10\n",
    "battery_add = 300\n",
    "\n",
    "matrix = np.tile(row, (num_vehicle, 1))\n",
    "\n",
    "# 初始化\n",
    "Vehicles = vehicle_generator(num_vehicle, num_city)\n",
    "orders_unmatched = {}\n",
    "G = CityGraph(num_city, 0.3, (10, 30))\n",
    "name = \"navie\"\n",
    "cancel_penalty = 300\n",
    "order_canceled = 0\n",
    "Total_order = {}\n",
    "\n",
    "# 设置s_0\n",
    "for time in range(TIME):\n",
    "    Orders = order_generator(num_order, time, num_city-1, CAPACITY, G ,speed)\n",
    "    for order in Orders.values():\n",
    "        Total_order[order.id] = order\n",
    "\n",
    "# 深复制最初的订单与车辆\n",
    "prim_order = copy.deepcopy(Total_order)\n",
    "prim_vehicle = copy.deepcopy(Vehicles)\n",
    "\"\"\"这里是强化学习部分\"\"\"\n",
    "# 超参数\n",
    "STATE_DIM_VEHICLE = 11   # 车辆状态的特征维度\n",
    "STATE_DIM_ORDER = 12     # 订单状态的特征维度\n",
    "HIDDEN_DIM = 128         # 隐藏层维度\n",
    "ACTION_DIM = num_city          # 动作空间维度\n",
    "ACTOR_LR = 1e-2          # Actor 学习率\n",
    "CRITIC_LR = 1e-2         # Critic 学习率\n",
    "GAMMA = 0.99             # 折扣因子\n",
    "NUM_EPISODES = 300     # 总训练轮数\n",
    "# 这里也改了\n",
    "STATE_DIM = 2 *HIDDEN_DIM       \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = magent.MultiAgentAC(\n",
    "    device = DEVICE,\n",
    "    VEHICLE_STATE_DIM = STATE_DIM_VEHICLE,\n",
    "    ORDER_STATE_DIM = STATE_DIM_ORDER, \n",
    "    NUM_CITIES = num_city, \n",
    "    HIDDEN_DIM = HIDDEN_DIM, \n",
    "    STATE_DIM = STATE_DIM\n",
    ")\n",
    "print(type(agent))\n",
    "grid_rewards = []\n",
    "# 开始计时\n",
    "start_time = tm.time()\n",
    "\n",
    "episode_reward = 0\n",
    "ACTIONS = []\n",
    "base_revenue = []\n",
    "first_revnue = []\n",
    "base_vehicle = []\n",
    "base_vehicle_class = []\n",
    "base_order_class = []\n",
    "base_city_node = []\n",
    "train_rewards = []\n",
    "burn_in = 100\n",
    "batch_time = int(TIME/2)\n",
    "for episode in range(NUM_EPISODES):\n",
    "    print(f\"第{episode}次训练\")\n",
    "    Total_order = copy.deepcopy(prim_order)\n",
    "    Vehicles = copy.deepcopy(prim_vehicle)\n",
    "    objval = 0\n",
    "    total_objval = 0\n",
    "    reward = 0\n",
    "    episode_reward = 0\n",
    "    invalid_time =  0\n",
    "    orders_unmatched = {} # 忘记加这个了\n",
    "    orders_virtual = {}\n",
    "    \n",
    "    if episode > 0:\n",
    "        # agent.load_model(load_path)\n",
    "        if episode > 1:\n",
    "            env.time = 0\n",
    "        \n",
    "        if episode < burn_in:\n",
    "            greedy_epsilon = 0.6\n",
    "            explore = True\n",
    "        else:\n",
    "            greedy_epsilon = 0.001\n",
    "            explore = False\n",
    "            if episode == burn_in:\n",
    "                best_model = train_rewards.index(max(train_rewards))\n",
    "                load_path = f\"rl_para/model_checkpoint_{best_model+1}.pth\"\n",
    "                agent = torch.load(load_path,map_location=\"cpu\")\n",
    "                print(f\"最优模型为{best_model}\")\n",
    "                agent.eval()\n",
    "            if episode > burn_in:\n",
    "                if train_rewards[best_model] > train_rewards[-1] or first_invalid < invalid_time:\n",
    "                    agent = torch.load(f'rl_para/model_checkpoint_{best_model+1}.pth',map_location=\"cpu\")\n",
    "                    print(f\"最优模型为{best_model}\")\n",
    "                    agent.eval()\n",
    "                else:\n",
    "                    best_model = train_rewards.index(train_rewards[-1]) \n",
    "                    agent = torch.load(f'rl_para/model_checkpoint_{best_model+1}.pth',map_location=\"cpu\")\n",
    "                    print(f\"最优模型为{best_model}\")\n",
    "                    agent.eval()\n",
    "    if_end = False\n",
    "    for time in range(batch_time):\n",
    "    \n",
    "        group = [[], []]\n",
    "        if time == batch_time -1:\n",
    "            if_end = True\n",
    "        # 按时间给出订单\n",
    "        for order in Total_order.values():\n",
    "            if order.start_time == time:\n",
    "                orders_unmatched[order.id] = order\n",
    "            # 加上这个代码后会导致性能降低\n",
    "            \"\"\"\n",
    "            if order.matched is False:\n",
    "                order.virtual_departure = order.departure \n",
    "            \"\"\"\n",
    "        if time != 0 and episode != 0:\n",
    "            next_vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 改了，不再是total_order\n",
    "            next_order_states = vectorization_order(orders_unmatched)\n",
    "            # 这里防止梯度爆炸缩小了reward\n",
    "            agent.update(vehicle_states, order_states, action,\n",
    "                         grid_reward, next_vehicle_states, next_order_states , if_end)\n",
    "            env.time = time\n",
    "        if time == 0 :\n",
    "            orders_virtual = orders_unmatched\n",
    "           \n",
    "            city_node = city_node_generator(G, orders_virtual, Vehicles, orders_unmatched)\n",
    "            if episode == 1 :\n",
    "                env = DispatchEnv(\n",
    "                    G=G,\n",
    "                    vehicles=Vehicles,\n",
    "                    orders=Total_order,\n",
    "                    cities=city_node,\n",
    "                    capacity=CAPACITY\n",
    "                )\n",
    "            elif episode > 1:\n",
    "                env.cities = city_node\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            if episode == 0:\n",
    "                city_update_without_drl(city_node , Vehicles, orders_unmatched ,time)\n",
    "            else:\n",
    "                city_update_without_drl(env.cities , Vehicles, orders_unmatched, time)\n",
    "            \n",
    "        if episode != 0:\n",
    "            \n",
    "            vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 这里也改了\n",
    "            order_states = vectorization_order(orders_unmatched)\n",
    "            \n",
    "            greedy = random.randint(0, 1)\n",
    "            if greedy > greedy_epsilon:\n",
    "                greedy = True\n",
    "            mask = env.get_mask(orders_unmatched)\n",
    "            action = agent.take_action_mask(vehicle_states, order_states, mask, explore, greedy)\n",
    "            reward = env.test_step(orders_unmatched,action)\n",
    "         \n",
    "            \"\"\"\n",
    "            COUNT = 1000\n",
    "            max_reward = -999999\n",
    "            max_action = action\n",
    "            \n",
    "           \n",
    "            while reward != 1000 and COUNT > 0:\n",
    "                greedy = random.randint(0, 1)\n",
    "                if greedy > greedy_epsilon:\n",
    "                    greedy = True\n",
    "                action = agent.take_action(vehicle_states, order_states, explore, greedy)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "                COUNT -= 1\n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    max_action = action\n",
    "            if COUNT == 0:\n",
    "                reward = env.test_step(orders_unmatched, max_action)\n",
    "            \"\"\"\n",
    "            \n",
    "           \n",
    "            \n",
    "            ACTIONS.append(action) \n",
    "            \"\"\"\n",
    "            while reward != 0 :\n",
    "                action = agent.take_action(vehicle_states, order_states)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "        for vehicle in Vehicles.values():\n",
    "            if vehicle.whether_city:\n",
    "                group[0].append(vehicle.id)\n",
    "            else:\n",
    "                group[1].append(vehicle.id)\n",
    "\n",
    "        if len(group[0]) != 0:\n",
    "\n",
    "            if episode == 0:\n",
    "                temp_Lower_Layer = Lower_Layer(G, city_node, Vehicles, orders_unmatched, name, group, time)\n",
    "            else:\n",
    "                temp_Lower_Layer = Lower_Layer(G, env.cities, Vehicles, orders_unmatched, name, group, time)\n",
    "            try:\n",
    "                temp_Lower_Layer.get_decision()\n",
    "                temp_Lower_Layer.constrain_1()\n",
    "                temp_Lower_Layer.constrain_2()\n",
    "                temp_Lower_Layer.constrain_3()\n",
    "                temp_Lower_Layer.constrain_4()\n",
    "                temp_Lower_Layer.constrain_5()\n",
    "                temp_Lower_Layer.model.setParam('OutputFlag', 0)\n",
    "                total_penalty = cancel_penalty * order_canceled\n",
    "                temp_Lower_Layer.set_objective(matrix)\n",
    "            \n",
    "                temp_Lower_Layer.model.optimize()\n",
    "\n",
    "                if temp_Lower_Layer.model.status == GRB.OPTIMAL:\n",
    "                    # save_results(temp_Lower_Layer,time)\n",
    "                    # print(\"Objective value:\", temp_Lower_Layer.model.objVal)\n",
    "                    objval = temp_Lower_Layer.model.objVal \n",
    "                else:\n",
    "                    temp_Lower_Layer.model.computeIIS()\n",
    "                    temp_Lower_Layer.model.write('iis.ilp')  # 保存不可行约束\n",
    "                    # print(f\"{time}次，No optimal solution found.\")\n",
    "                    self_update(Vehicles, G)\n",
    "                    objval = basic_cost(Vehicles, orders_unmatched)\n",
    "                    \n",
    "                \n",
    "                _, var_order = temp_Lower_Layer.get_decision()\n",
    "                update_var(temp_Lower_Layer, Vehicles, orders_unmatched)\n",
    "                vehicle_in_city = update_vehicle(Vehicles, battery_consume, battery_add, speed, G)\n",
    "                order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            except:\n",
    "                self_update(Vehicles, G)\n",
    "               \n",
    "                order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "                objval = - basic_cost(Vehicles, orders_unmatched)\n",
    "                invalid_time += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self_update(Vehicles, G)\n",
    "            # print(f\"{episode}轮，{time}次，{len(group[1])}辆车不在城市\")\n",
    "            order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            objval = - basic_cost(Vehicles, orders_unmatched)\n",
    "            # 利润（如果有）减去新增的取消订单\n",
    "            \n",
    "            invalid_time += 1\n",
    "        objval = objval - update_order(orders_unmatched, time, speed) * cancel_penalty\n",
    "        if episode != 0: \n",
    "            \n",
    "            # 防止梯度爆炸\n",
    "            grid_reward =   objval\n",
    "            grid_rewards.append(reward)\n",
    "            # print(grid_reward)\n",
    "            episode_reward += reward + objval\n",
    "        total_objval += objval\n",
    "\n",
    "        if episode == 0:\n",
    "            base_revenue.append(objval)\n",
    "            base_vehicle.append(copy.deepcopy(group[0]))\n",
    "            # base_vehicle_class.append(copy.deepcopy(Vehicles))\n",
    "            # base_order_class.append(copy.deepcopy(Total_order))\n",
    "            \n",
    "            base_city_node.append(copy.deepcopy(city_node))\n",
    "            \"\"\"\n",
    "            if episode == 1:\n",
    "                first_revnue.append(objval)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # if base_revenue[time] != objval:\n",
    "            #    print(\"base_revenue\",time, objval,base_revenue[time])\n",
    "            # if first_revnue[time] != objval:\n",
    "            #    print(\"first_revenue\",time, first_revnue[time], objval)\n",
    "            \"\"\" \n",
    "            if base_vehicle[time] != group[0]:\n",
    "                print(\"vehicle is different\", len(base_vehicle[time]), len(group[0]))\n",
    "            if base_city_node[time] != env.cities:\n",
    "                print(time, base_city_node[time],\"\\n\", env.cities)\n",
    "            \"\"\"\n",
    "            \n",
    "        # print(f\"{len(orders_unmatched)}订单未被匹配,{order_canceled}订单超时,总利润为{objval},强化学习利润为{reward}\")\n",
    "    end_time = tm.time()\n",
    "    execution_time = end_time - start_time\n",
    "    if episode != 0:\n",
    "        print(f\"执行时间: {execution_time} 秒,{invalid_time}次未求解，当前强化学习值为{episode_reward},利润为{total_objval}\")\n",
    "        # torch.save(agent.state_dict(), 'model_checkpoint.pth')\n",
    "        save_path = f\"rl_para/model_checkpoint_{episode}.pth\"\n",
    "        torch.save(agent, save_path)\n",
    "        train_rewards.append(total_objval)\n",
    "        first_invalid = invalid_time\n",
    "    else:\n",
    "        print(f\"未加强化学习利润为{total_objval},{invalid_time}次未求解\")\n",
    "    # grid_rewards.append(0)\n",
    "    # save_path = f\"actor_critic_model{episode}.pth\"\n",
    "    # load_path = f\"actor_critic_model{episode}.pth\"\n",
    "    \n",
    "plt.plot(grid_rewards, label='Grid Reward Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Grid Reward')\n",
    "plt.title('Reward Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# print(find_duplicates_with_positions(ACTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带跳过的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'multiagent.MultiAgentAC'>\n",
      "第0次训练\n",
      "Set parameter LicenseID to value 2584673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Set parameter LicenseID to value 2584673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未加强化学习利润为351240.0,48次未求解\n",
      "第1次训练\n",
      "执行时间: 1.5951976776123047 秒,66次未求解，当前强化学习值为-316088.0,利润为-1388.0\n",
      "第2次训练\n",
      "执行时间: 2.8220858573913574 秒,40次未求解，当前强化学习值为255049.0,利润为471649.0\n",
      "第3次训练\n",
      "执行时间: 3.92783522605896 秒,48次未求解，当前强化学习值为76507.0,利润为333107.0\n",
      "第4次训练\n",
      "执行时间: 4.801097393035889 秒,60次未求解，当前强化学习值为-187197.0,利润为108603.0\n",
      "第5次训练\n",
      "执行时间: 6.016491651535034 秒,45次未求解，当前强化学习值为168199.0,利润为405999.0\n",
      "第6次训练\n",
      "执行时间: 6.894177436828613 秒,60次未求解，当前强化学习值为-183913.0,利润为112087.0\n",
      "第7次训练\n",
      "执行时间: 7.8495588302612305 秒,60次未求解，当前强化学习值为-186198.0,利润为108602.0\n",
      "第8次训练\n",
      "执行时间: 9.370670318603516 秒,43次未求解，当前强化学习值为195294.0,利润为423494.0\n",
      "第9次训练\n",
      "执行时间: 10.391007423400879 秒,59次未求解，当前强化学习值为-181762.0,利润为112638.0\n",
      "第10次训练\n",
      "执行时间: 11.553189754486084 秒,57次未求解，当前强化学习值为-102270.0,利润为178130.0\n",
      "第11次训练\n",
      "执行时间: 13.124795198440552 秒,47次未求解，当前强化学习值为114564.0,利润为361264.0\n",
      "第12次训练\n",
      "执行时间: 14.306801080703735 秒,60次未求解，当前强化学习值为-180413.0,利润为112087.0\n",
      "第13次训练\n",
      "执行时间: 15.57046389579773 秒,48次未求解，当前强化学习值为68873.0,利润为326673.0\n",
      "第14次训练\n",
      "执行时间: 16.64451813697815 秒,57次未求解，当前强化学习值为-110057.0,利润为170643.0\n",
      "第15次训练\n",
      "执行时间: 17.640617847442627 秒,59次未求解，当前强化学习值为-159380.0,利润为131420.0\n",
      "第16次训练\n",
      "执行时间: 18.647897958755493 秒,59次未求解，当前强化学习值为-168057.0,利润为127243.0\n",
      "第17次训练\n",
      "执行时间: 20.608492374420166 秒,28次未求解，当前强化学习值为534251.0,利润为696851.0\n",
      "第18次训练\n",
      "执行时间: 21.51712131500244 秒,60次未求解，当前强化学习值为-190784.0,利润为105716.0\n",
      "第19次训练\n",
      "执行时间: 22.778335571289062 秒,48次未求解，当前强化学习值为80027.0,利润为333427.0\n",
      "第20次训练\n",
      "执行时间: 23.744807720184326 秒,60次未求解，当前强化学习值为-184613.0,利润为112087.0\n",
      "第21次训练\n",
      "执行时间: 24.99462080001831 秒,51次未求解，当前强化学习值为23549.0,利润为288049.0\n",
      "第22次训练\n",
      "执行时间: 25.945756196975708 秒,60次未求解，当前强化学习值为-187566.0,利润为107234.0\n",
      "第23次训练\n",
      "执行时间: 27.99422001838684 秒,23次未求解，当前强化学习值为649226.0,利润为800126.0\n",
      "第24次训练\n",
      "执行时间: 29.752153396606445 秒,32次未求解，当前强化学习值为436038.0,利润为620738.0\n",
      "第25次训练\n",
      "执行时间: 31.028327465057373 秒,47次未求解，当前强化学习值为129301.0,利润为373001.0\n",
      "第26次训练\n",
      "执行时间: 32.439204454422 秒,45次未求解，当前强化学习值为158061.0,利润为394861.0\n",
      "第27次训练\n",
      "执行时间: 33.439168214797974 秒,57次未求解，当前强化学习值为-118950.0,利润为164950.0\n",
      "第28次训练\n",
      "执行时间: 34.552332639694214 秒,54次未求解，当前强化学习值为-59392.0,利润为217108.0\n",
      "第29次训练\n",
      "执行时间: 35.700438261032104 秒,54次未求解，当前强化学习值为-63310.0,利润为215190.0\n",
      "第30次训练\n",
      "执行时间: 36.633397817611694 秒,60次未求解，当前强化学习值为-187284.0,利润为105716.0\n",
      "第31次训练\n",
      "执行时间: 38.67721676826477 秒,22次未求解，当前强化学习值为680635.0,利润为824735.0\n",
      "第32次训练\n",
      "执行时间: 39.634028673172 秒,60次未求解，当前强化学习值为-187925.0,利润为108375.0\n",
      "第33次训练\n",
      "执行时间: 41.42440843582153 秒,35次未求解，当前强化学习值为369561.0,利润为567161.0\n",
      "第34次训练\n",
      "执行时间: 42.37771916389465 秒,60次未求解，当前强化学习值为-193384.0,利润为105716.0\n",
      "第35次训练\n",
      "执行时间: 43.3869833946228 秒,58次未求解，当前强化学习值为-129827.0,利润为155773.0\n",
      "第36次训练\n",
      "执行时间: 45.71844553947449 秒,11次未求解，当前强化学习值为902113.0,利润为1014313.0\n",
      "第37次训练\n",
      "执行时间: 46.916133403778076 秒,50次未求解，当前强化学习值为43715.0,利润为306115.0\n",
      "第38次训练\n",
      "执行时间: 48.783586502075195 秒,28次未求解，当前强化学习值为548164.0,利润为711764.0\n",
      "第39次训练\n",
      "执行时间: 49.75050187110901 秒,60次未求解，当前强化学习值为-191724.0,利润为108376.0\n",
      "第40次训练\n",
      "执行时间: 51.13849878311157 秒,43次未求解，当前强化学习值为195591.0,利润为421091.0\n",
      "第41次训练\n",
      "执行时间: 52.136146783828735 秒,57次未求解，当前强化学习值为-116542.0,利润为164658.0\n",
      "第42次训练\n",
      "执行时间: 53.34069466590881 秒,51次未求解，当前强化学习值为22358.0,利润为286358.0\n",
      "第43次训练\n",
      "执行时间: 54.45970129966736 秒,53次未求解，当前强化学习值为-46247.0,利润为229853.0\n",
      "第44次训练\n",
      "执行时间: 55.403913497924805 秒,60次未求解，当前强化学习值为-184125.0,利润为108375.0\n",
      "第45次训练\n",
      "执行时间: 56.32914471626282 秒,60次未求解，当前强化学习值为-194084.0,利润为105716.0\n",
      "第46次训练\n",
      "执行时间: 57.52802777290344 秒,50次未求解，当前强化学习值为22843.0,利润为285343.0\n",
      "第47次训练\n",
      "执行时间: 59.19414758682251 秒,34次未求解，当前强化学习值为410426.0,利润为602826.0\n",
      "第48次训练\n",
      "执行时间: 60.40188717842102 秒,50次未求解，当前强化学习值为54377.0,利润为313777.0\n",
      "第49次训练\n",
      "执行时间: 62.1056182384491 秒,36次未求解，当前强化学习值为353559.0,利润为554559.0\n",
      "第50次训练\n",
      "执行时间: 63.049800157547 秒,60次未求解，当前强化学习值为-187625.0,利润为108375.0\n",
      "第51次训练\n",
      "执行时间: 64.5289478302002 秒,41次未求解，当前强化学习值为236401.0,利润为457601.0\n",
      "第52次训练\n",
      "执行时间: 65.51738786697388 秒,58次未求解，当前强化学习值为-135383.0,利润为147517.0\n",
      "第53次训练\n",
      "执行时间: 67.07062864303589 秒,38次未求解，当前强化学习值为285800.0,利润为499800.0\n",
      "第54次训练\n",
      "执行时间: 68.92661738395691 秒,31次未求解，当前强化学习值为477191.0,利润为654391.0\n",
      "第55次训练\n",
      "执行时间: 70.24348044395447 秒,48次未求解，当前强化学习值为86877.0,利润为339677.0\n",
      "第56次训练\n",
      "执行时间: 71.25049686431885 秒,60次未求解，当前强化学习值为-189797.0,利润为108603.0\n",
      "第57次训练\n",
      "执行时间: 72.19648313522339 秒,60次未求解，当前强化学习值为-186590.0,利润为112310.0\n",
      "第58次训练\n",
      "执行时间: 73.2587080001831 秒,55次未求解，当前强化学习值为-77222.0,利润为201478.0\n",
      "第59次训练\n",
      "执行时间: 74.27636647224426 秒,58次未求解，当前强化学习值为-131425.0,利润为155775.0\n",
      "第60次训练\n",
      "执行时间: 75.9955050945282 秒,32次未求解，当前强化学习值为424336.0,利润为609836.0\n",
      "第61次训练\n",
      "执行时间: 77.16693782806396 秒,54次未求解，当前强化学习值为-50641.0,利润为226659.0\n",
      "第62次训练\n",
      "执行时间: 78.11392188072205 秒,60次未求解，当前强化学习值为-188324.0,利润为108376.0\n",
      "第63次训练\n",
      "执行时间: 79.20863389968872 秒,57次未求解，当前强化学习值为-113257.0,利润为170643.0\n",
      "第64次训练\n",
      "执行时间: 80.21722507476807 秒,58次未求解，当前强化学习值为-134936.0,利润为150664.0\n",
      "第65次训练\n",
      "执行时间: 81.21145439147949 秒,58次未求解，当前强化学习值为-133954.0,利润为149646.0\n",
      "第66次训练\n",
      "执行时间: 82.88465523719788 秒,35次未求解，当前强化学习值为388026.0,利润为581726.0\n",
      "第67次训练\n",
      "执行时间: 83.94495129585266 秒,55次未求解，当前强化学习值为-82790.0,利润为194710.0\n",
      "第68次训练\n",
      "执行时间: 84.91909193992615 秒,60次未求解，当前强化学习值为-189397.0,利润为108603.0\n",
      "第69次训练\n",
      "执行时间: 86.38045382499695 秒,41次未求解，当前强化学习值为235517.0,利润为455017.0\n",
      "第70次训练\n",
      "执行时间: 87.39861249923706 秒,60次未求解，当前强化学习值为-183013.0,利润为112087.0\n",
      "第71次训练\n",
      "执行时间: 88.33405995368958 秒,59次未求解，当前强化学习值为-181862.0,利润为112638.0\n",
      "第72次训练\n",
      "执行时间: 89.58133697509766 秒,51次未求解，当前强化学习值为19955.0,利润为288055.0\n",
      "第73次训练\n",
      "执行时间: 91.56137347221375 秒,23次未求解，当前强化学习值为667000.0,利润为816100.0\n",
      "第74次训练\n",
      "执行时间: 92.61986470222473 秒,58次未求解，当前强化学习值为-135307.0,利润为152993.0\n",
      "第75次训练\n",
      "执行时间: 93.57529735565186 秒,60次未求解，当前强化学习值为-189684.0,利润为105716.0\n",
      "第76次训练\n",
      "执行时间: 94.529616355896 秒,60次未求解，当前强化学习值为-188425.0,利润为108375.0\n",
      "第77次训练\n",
      "执行时间: 95.49549078941345 秒,60次未求解，当前强化学习值为-187397.0,利润为108603.0\n",
      "第78次训练\n",
      "执行时间: 96.7206883430481 秒,47次未求解，当前强化学习值为87333.0,利润为338433.0\n",
      "第79次训练\n",
      "执行时间: 97.80291867256165 秒,55次未求解，当前强化学习值为-72993.0,利润为206507.0\n",
      "第80次训练\n",
      "执行时间: 98.76064229011536 秒,60次未求解，当前强化学习值为-185213.0,利润为112087.0\n",
      "第81次训练\n",
      "执行时间: 99.71186685562134 秒,60次未求解，当前强化学习值为-188866.0,利润为107834.0\n",
      "第82次训练\n",
      "执行时间: 101.1367130279541 秒,44次未求解，当前强化学习值为168940.0,利润为403940.0\n",
      "第83次训练\n",
      "执行时间: 102.72883558273315 秒,37次未求解，当前强化学习值为302257.0,利润为513357.0\n",
      "第84次训练\n",
      "执行时间: 103.68984532356262 秒,60次未求解，当前强化学习值为-185397.0,利润为108603.0\n",
      "第85次训练\n",
      "执行时间: 104.7415132522583 秒,60次未求解，当前强化学习值为-187524.0,利润为108376.0\n",
      "第86次训练\n",
      "执行时间: 105.96233081817627 秒,51次未求解，当前强化学习值为35023.0,利润为293323.0\n",
      "第87次训练\n",
      "执行时间: 106.89941883087158 秒,60次未求解，当前强化学习值为-185897.0,利润为108603.0\n",
      "第88次训练\n",
      "执行时间: 107.8716242313385 秒,60次未求解，当前强化学习值为-186790.0,利润为112310.0\n",
      "第89次训练\n",
      "执行时间: 108.86753177642822 秒,60次未求解，当前强化学习值为-189598.0,利润为108602.0\n",
      "第90次训练\n",
      "执行时间: 110.29196691513062 秒,43次未求解，当前强化学习值为176044.0,利润为412544.0\n",
      "第91次训练\n",
      "执行时间: 111.2357029914856 秒,60次未求解，当前强化学习值为-187525.0,利润为108375.0\n",
      "第92次训练\n",
      "执行时间: 112.51746869087219 秒,50次未求解，当前强化学习值为55062.0,利润为308862.0\n",
      "第93次训练\n",
      "执行时间: 113.96824717521667 秒,43次未求解，当前强化学习值为179440.0,利润为413340.0\n",
      "第94次训练\n",
      "执行时间: 115.20708656311035 秒,54次未求解，当前强化学习值为-46443.0,利润为228857.0\n",
      "第95次训练\n",
      "执行时间: 116.19106864929199 秒,60次未求解，当前强化学习值为-191197.0,利润为108603.0\n",
      "第96次训练\n",
      "执行时间: 117.2844717502594 秒,54次未求解，当前强化学习值为-49093.0,利润为226707.0\n",
      "第97次训练\n",
      "执行时间: 118.26419067382812 秒,60次未求解，当前强化学习值为-188684.0,利润为105716.0\n",
      "第98次训练\n",
      "执行时间: 119.45181608200073 秒,51次未求解，当前强化学习值为25755.0,利润为288455.0\n",
      "第99次训练\n",
      "执行时间: 120.3560893535614 秒,60次未求解，当前强化学习值为-184166.0,利润为107834.0\n",
      "第100次训练\n",
      "最优模型为35\n",
      "执行时间: 121.3204836845398 秒,60次未求解，当前强化学习值为-196920.0,利润为104480.0\n",
      "第101次训练\n",
      "最优模型为35\n",
      "执行时间: 122.23788475990295 秒,60次未求解，当前强化学习值为-192184.0,利润为105716.0\n",
      "第102次训练\n",
      "最优模型为35\n",
      "执行时间: 123.19744944572449 秒,60次未求解，当前强化学习值为-185214.0,利润为112086.0\n",
      "第103次训练\n",
      "最优模型为35\n",
      "执行时间: 124.13381385803223 秒,60次未求解，当前强化学习值为-191384.0,利润为105716.0\n",
      "第104次训练\n",
      "最优模型为35\n",
      "执行时间: 125.08623027801514 秒,60次未求解，当前强化学习值为-186925.0,利润为108375.0\n",
      "第105次训练\n",
      "最优模型为35\n",
      "执行时间: 126.30799269676208 秒,48次未求解，当前强化学习值为79958.0,利润为334558.0\n",
      "第106次训练\n",
      "最优模型为35\n",
      "执行时间: 128.32657599449158 秒,23次未求解，当前强化学习值为639598.0,利润为791798.0\n",
      "第107次训练\n",
      "最优模型为35\n",
      "执行时间: 129.66857504844666 秒,47次未求解，当前强化学习值为98970.99993335613,利润为357870.9999333561\n",
      "第108次训练\n",
      "最优模型为35\n",
      "执行时间: 130.82310009002686 秒,58次未求解，当前强化学习值为-143817.0,利润为146083.0\n",
      "第109次训练\n",
      "最优模型为35\n",
      "执行时间: 131.8901650905609 秒,58次未求解，当前强化学习值为-136629.0,利润为152071.0\n",
      "第110次训练\n",
      "最优模型为35\n",
      "执行时间: 134.40908408164978 秒,7次未求解，当前强化学习值为983056.0,利润为1087856.0\n",
      "第111次训练\n",
      "最优模型为35\n",
      "执行时间: 135.56054759025574 秒,58次未求解，当前强化学习值为-137837.0,利润为150663.0\n",
      "第112次训练\n",
      "最优模型为35\n",
      "执行时间: 136.64506363868713 秒,60次未求解，当前强化学习值为-186825.0,利润为108375.0\n",
      "第113次训练\n",
      "最优模型为35\n",
      "执行时间: 137.77993845939636 秒,54次未求解，当前强化学习值为-60230.0,利润为219370.0\n",
      "第114次训练\n",
      "最优模型为35\n",
      "执行时间: 139.00611233711243 秒,59次未求解，当前强化学习值为-165156.0,利润为127244.0\n",
      "第115次训练\n",
      "最优模型为35\n",
      "执行时间: 140.6410892009735 秒,48次未求解，当前强化学习值为86041.0,利润为339341.0\n",
      "第116次训练\n",
      "最优模型为35\n",
      "执行时间: 142.40051746368408 秒,35次未求解，当前强化学习值为376823.0,利润为571523.0\n",
      "第117次训练\n",
      "最优模型为35\n",
      "执行时间: 143.57704281806946 秒,53次未求解，当前强化学习值为-48617.0,利润为224883.0\n",
      "第118次训练\n",
      "最优模型为35\n",
      "执行时间: 145.75464940071106 秒,21次未求解，当前强化学习值为670918.0,利润为821018.0\n",
      "第119次训练\n",
      "最优模型为35\n",
      "执行时间: 147.02079129219055 秒,50次未求解，当前强化学习值为50265.0,利润为305165.0\n",
      "第120次训练\n",
      "最优模型为35\n",
      "执行时间: 148.03165912628174 秒,60次未求解，当前强化学习值为-191624.0,利润为108376.0\n",
      "第121次训练\n",
      "最优模型为35\n",
      "执行时间: 149.89130783081055 秒,27次未求解，当前强化学习值为552953.0,利润为719653.0\n",
      "第122次训练\n",
      "最优模型为35\n",
      "执行时间: 151.05049443244934 秒,45次未求解，当前强化学习值为160090.0,利润为396590.0\n",
      "第123次训练\n",
      "最优模型为35\n",
      "执行时间: 151.98367047309875 秒,60次未求解，当前强化学习值为-191197.0,利润为108603.0\n",
      "第124次训练\n",
      "最优模型为35\n",
      "执行时间: 152.91549134254456 秒,58次未求解，当前强化学习值为-134437.0,利润为150663.0\n",
      "第125次训练\n",
      "最优模型为35\n",
      "执行时间: 154.26281690597534 秒,38次未求解，当前强化学习值为302843.0,利润为512143.0\n",
      "第126次训练\n",
      "最优模型为35\n",
      "执行时间: 155.22281908988953 秒,58次未求解，当前强化学习值为-136437.0,利润为150663.0\n",
      "第127次训练\n",
      "最优模型为35\n",
      "执行时间: 156.25933933258057 秒,52次未求解，当前强化学习值为-13601.0,利润为256899.0\n",
      "第128次训练\n",
      "最优模型为35\n",
      "执行时间: 157.1459345817566 秒,58次未求解，当前强化学习值为-143435.0,利润为143665.0\n",
      "第129次训练\n",
      "最优模型为35\n",
      "执行时间: 158.03922820091248 秒,60次未求解，当前强化学习值为-187925.0,利润为108375.0\n",
      "第130次训练\n",
      "最优模型为35\n",
      "执行时间: 158.92097401618958 秒,60次未求解，当前强化学习值为-193284.0,利润为105716.0\n",
      "第131次训练\n",
      "最优模型为35\n",
      "执行时间: 159.84232568740845 秒,60次未求解，当前强化学习值为-185489.0,利润为112311.0\n",
      "第132次训练\n",
      "最优模型为35\n",
      "执行时间: 160.9287087917328 秒,54次未求解，当前强化学习值为-55947.0,利润为224053.0\n",
      "第133次训练\n",
      "最优模型为35\n",
      "执行时间: 162.09905314445496 秒,51次未求解，当前强化学习值为27708.0,利润为290308.0\n",
      "第134次训练\n",
      "最优模型为35\n",
      "执行时间: 163.93159818649292 秒,18次未求解，当前强化学习值为766780.0,利润为900680.0\n",
      "第135次训练\n",
      "最优模型为35\n",
      "执行时间: 164.9489631652832 秒,60次未求解，当前强化学习值为-187066.0,利润为107834.0\n",
      "第136次训练\n",
      "最优模型为35\n",
      "执行时间: 166.57515454292297 秒,37次未求解，当前强化学习值为310584.0,利润为519484.0\n",
      "第137次训练\n",
      "最优模型为35\n",
      "执行时间: 167.5441632270813 秒,60次未求解，当前强化学习值为-183913.0,利润为112087.0\n",
      "第138次训练\n",
      "最优模型为35\n",
      "执行时间: 168.517085313797 秒,60次未求解，当前强化学习值为-181515.0,利润为112085.0\n",
      "第139次训练\n",
      "最优模型为35\n",
      "执行时间: 169.47752785682678 秒,60次未求解，当前强化学习值为-189025.0,利润为108375.0\n",
      "第140次训练\n",
      "最优模型为35\n",
      "执行时间: 170.4704098701477 秒,58次未求解，当前强化学习值为-145145.0,利润为143955.0\n",
      "第141次训练\n",
      "最优模型为35\n",
      "执行时间: 171.61494302749634 秒,57次未求解，当前强化学习值为-123261.0,利润为163339.0\n",
      "第142次训练\n",
      "最优模型为35\n",
      "执行时间: 172.6714940071106 秒,56次未求解，当前强化学习值为-82394.0,利润为196206.0\n",
      "第143次训练\n",
      "最优模型为35\n",
      "执行时间: 174.24093580245972 秒,40次未求解，当前强化学习值为265885.0,利润为482185.0\n",
      "第144次训练\n",
      "最优模型为35\n",
      "执行时间: 175.2280457019806 秒,59次未求解，当前强化学习值为-164656.0,利润为127244.0\n",
      "第145次训练\n",
      "最优模型为35\n",
      "执行时间: 177.02452993392944 秒,30次未求解，当前强化学习值为494887.0,利润为671987.0\n",
      "第146次训练\n",
      "最优模型为35\n",
      "执行时间: 178.81011962890625 秒,32次未求解，当前强化学习值为454655.0,利润为637055.0\n",
      "第147次训练\n",
      "最优模型为35\n",
      "执行时间: 179.76635479927063 秒,60次未求解，当前强化学习值为-184214.0,利润为112086.0\n",
      "第148次训练\n",
      "最优模型为35\n",
      "执行时间: 180.75130462646484 秒,60次未求解，当前强化学习值为-184889.0,利润为112311.0\n",
      "第149次训练\n",
      "最优模型为35\n",
      "执行时间: 181.89295649528503 秒,51次未求解，当前强化学习值为17677.0,利润为282877.0\n",
      "第150次训练\n",
      "最优模型为35\n",
      "执行时间: 182.9985318183899 秒,54次未求解，当前强化学习值为-56781.0,利润为219019.0\n",
      "第151次训练\n",
      "最优模型为35\n",
      "执行时间: 184.2939157485962 秒,48次未求解，当前强化学习值为107515.0,利润为354815.0\n",
      "第152次训练\n",
      "最优模型为35\n",
      "执行时间: 185.66520404815674 秒,43次未求解，当前强化学习值为196426.0,利润为428626.0\n",
      "第153次训练\n",
      "最优模型为35\n",
      "执行时间: 186.6812460422516 秒,58次未求解，当前强化学习值为-137489.0,利润为147511.0\n",
      "第154次训练\n",
      "最优模型为35\n",
      "执行时间: 187.61258220672607 秒,60次未求解，当前强化学习值为-192720.0,利润为104480.0\n",
      "第155次训练\n",
      "最优模型为35\n",
      "执行时间: 188.56989240646362 秒,60次未求解，当前强化学习值为-195420.0,利润为104480.0\n",
      "第156次训练\n",
      "最优模型为35\n",
      "执行时间: 189.5723340511322 秒,58次未求解，当前强化学习值为-135482.0,利润为147518.0\n",
      "第157次训练\n",
      "最优模型为35\n",
      "执行时间: 190.57703518867493 秒,59次未求解，当前强化学习值为-162056.0,利润为127244.0\n",
      "第158次训练\n",
      "最优模型为35\n",
      "执行时间: 191.57029938697815 秒,58次未求解，当前强化学习值为-131497.0,利润为151303.0\n",
      "第159次训练\n",
      "最优模型为35\n",
      "执行时间: 193.18104481697083 秒,37次未求解，当前强化学习值为314272.0,利润为528572.0\n",
      "第160次训练\n",
      "最优模型为35\n",
      "执行时间: 194.1245415210724 秒,60次未求解，当前强化学习值为-192543.0,利润为104257.0\n",
      "第161次训练\n",
      "最优模型为35\n",
      "执行时间: 196.5143163204193 秒,9次未求解，当前强化学习值为990179.0,利润为1085879.0\n",
      "第162次训练\n",
      "最优模型为35\n",
      "执行时间: 197.64509797096252 秒,58次未求解，当前强化学习值为-129827.0,利润为155773.0\n",
      "第163次训练\n",
      "最优模型为35\n",
      "执行时间: 198.55867409706116 秒,60次未求解，当前强化学习值为-183925.0,利润为108375.0\n",
      "第164次训练\n",
      "最优模型为35\n",
      "执行时间: 199.6782088279724 秒,58次未求解，当前强化学习值为-146245.0,利润为143955.0\n",
      "第165次训练\n",
      "最优模型为35\n",
      "执行时间: 200.66531991958618 秒,59次未求解，当前强化学习值为-166653.0,利润为127247.0\n",
      "第166次训练\n",
      "最优模型为35\n",
      "执行时间: 201.62729954719543 秒,60次未求解，当前强化学习值为-186589.0,利润为112311.0\n",
      "第167次训练\n",
      "最优模型为35\n",
      "执行时间: 202.84313583374023 秒,51次未求解，当前强化学习值为36776.0,利润为297976.0\n",
      "第168次训练\n",
      "最优模型为35\n",
      "执行时间: 203.75165796279907 秒,60次未求解，当前强化学习值为-185115.0,利润为112085.0\n",
      "第169次训练\n",
      "最优模型为35\n",
      "执行时间: 205.69684290885925 秒,6次未求解，当前强化学习值为1047551.0,利润为1136751.0\n",
      "第170次训练\n",
      "最优模型为35\n",
      "执行时间: 206.5575942993164 秒,60次未求解，当前强化学习值为-188198.0,利润为108602.0\n",
      "第171次训练\n",
      "最优模型为35\n",
      "执行时间: 207.49178290367126 秒,58次未求解，当前强化学习值为-148817.0,利润为146083.0\n",
      "第172次训练\n",
      "最优模型为35\n",
      "执行时间: 208.49127411842346 秒,60次未求解，当前强化学习值为-189425.0,利润为108375.0\n",
      "第173次训练\n",
      "最优模型为35\n",
      "执行时间: 209.3841781616211 秒,58次未求解，当前强化学习值为-139403.0,利润为152997.0\n",
      "第174次训练\n",
      "最优模型为35\n",
      "执行时间: 210.64575910568237 秒,43次未求解，当前强化学习值为169834.0,利润为408134.0\n",
      "第175次训练\n",
      "最优模型为35\n",
      "执行时间: 211.51969575881958 秒,60次未求解，当前强化学习值为-193766.0,利润为107234.0\n",
      "第176次训练\n",
      "最优模型为35\n",
      "执行时间: 212.39733839035034 秒,58次未求解，当前强化学习值为-138903.0,利润为145397.0\n",
      "第177次训练\n",
      "最优模型为35\n",
      "执行时间: 213.3943166732788 秒,54次未求解，当前强化学习值为-56505.0,利润为221195.0\n",
      "第178次训练\n",
      "最优模型为35\n",
      "执行时间: 214.3564896583557 秒,54次未求解，当前强化学习值为-58473.0,利润为222027.0\n",
      "第179次训练\n",
      "最优模型为35\n",
      "执行时间: 215.46778202056885 秒,45次未求解，当前强化学习值为152563.0,利润为390763.0\n",
      "第180次训练\n",
      "最优模型为35\n",
      "执行时间: 216.35304832458496 秒,60次未求解，当前强化学习值为-190566.0,利润为107834.0\n",
      "第181次训练\n",
      "最优模型为35\n",
      "执行时间: 217.1901683807373 秒,60次未求解，当前强化学习值为-189566.0,利润为107834.0\n",
      "第182次训练\n",
      "最优模型为35\n",
      "执行时间: 218.28790140151978 秒,47次未求解，当前强化学习值为102841.0,利润为351441.0\n",
      "第183次训练\n",
      "最优模型为35\n",
      "执行时间: 219.1589617729187 秒,60次未求解，当前强化学习值为-186188.0,利润为112312.0\n",
      "第184次训练\n",
      "最优模型为35\n",
      "执行时间: 220.04464960098267 秒,58次未求解，当前强化学习值为-137583.0,利润为149517.0\n",
      "第185次训练\n",
      "最优模型为35\n",
      "执行时间: 220.87177443504333 秒,60次未求解，当前强化学习值为-185797.0,利润为108603.0\n",
      "第186次训练\n",
      "最优模型为35\n",
      "执行时间: 221.76338267326355 秒,58次未求解，当前强化学习值为-136153.0,利润为149647.0\n",
      "第187次训练\n",
      "最优模型为35\n",
      "执行时间: 222.57552814483643 秒,60次未求解，当前强化学习值为-195184.0,利润为105716.0\n",
      "第188次训练\n",
      "最优模型为35\n",
      "执行时间: 223.44258451461792 秒,59次未求解，当前强化学习值为-161479.0,利润为129321.0\n",
      "第189次训练\n",
      "最优模型为35\n",
      "执行时间: 224.59621119499207 秒,43次未求解，当前强化学习值为178706.0,利润为416006.0\n",
      "第190次训练\n",
      "最优模型为35\n",
      "执行时间: 225.45598483085632 秒,60次未求解，当前强化学习值为-192425.0,利润为108375.0\n",
      "第191次训练\n",
      "最优模型为35\n",
      "执行时间: 226.28961968421936 秒,60次未求解，当前强化学习值为-189966.0,利润为107834.0\n",
      "第192次训练\n",
      "最优模型为35\n",
      "执行时间: 228.23953676223755 秒,31次未求解，当前强化学习值为482222.0,利润为660722.0\n",
      "第193次训练\n",
      "最优模型为35\n",
      "执行时间: 229.31199431419373 秒,59次未求解，当前强化学习值为-165180.0,利润为129320.0\n",
      "第194次训练\n",
      "最优模型为35\n",
      "执行时间: 230.2102234363556 秒,60次未求解，当前强化学习值为-182688.0,利润为112312.0\n",
      "第195次训练\n",
      "最优模型为35\n",
      "执行时间: 231.1345226764679 秒,60次未求解，当前强化学习值为-181087.0,利润为112313.0\n",
      "第196次训练\n",
      "最优模型为35\n",
      "执行时间: 232.0563771724701 秒,60次未求解，当前强化学习值为-192484.0,利润为105716.0\n",
      "第197次训练\n",
      "最优模型为35\n",
      "执行时间: 233.13523602485657 秒,51次未求解，当前强化学习值为38378.0,利润为297678.0\n",
      "第198次训练\n",
      "最优模型为35\n",
      "执行时间: 233.98434162139893 秒,60次未求解，当前强化学习值为-191384.0,利润为105716.0\n",
      "第199次训练\n",
      "最优模型为35\n",
      "执行时间: 235.4276783466339 秒,34次未求解，当前强化学习值为398089.0,利润为596089.0\n",
      "第200次训练\n",
      "最优模型为35\n",
      "执行时间: 236.49652671813965 秒,51次未求解，当前强化学习值为42467.0,利润为296067.0\n",
      "第201次训练\n",
      "最优模型为35\n",
      "执行时间: 237.3912591934204 秒,58次未求解，当前强化学习值为-137200.0,利润为151300.0\n",
      "第202次训练\n",
      "最优模型为35\n",
      "执行时间: 238.45400261878967 秒,52次未求解，当前强化学习值为-18412.0,利润为255788.0\n",
      "第203次训练\n",
      "最优模型为35\n",
      "执行时间: 239.55296993255615 秒,47次未求解，当前强化学习值为117494.0,利润为364394.0\n",
      "第204次训练\n",
      "最优模型为35\n",
      "执行时间: 240.5828664302826 秒,51次未求解，当前强化学习值为9457.0,利润为275757.0\n",
      "第205次训练\n",
      "最优模型为35\n",
      "执行时间: 241.49330592155457 秒,60次未求解，当前强化学习值为-190498.0,利润为108602.0\n",
      "第206次训练\n",
      "最优模型为35\n",
      "执行时间: 242.33976364135742 秒,60次未求解，当前强化学习值为-183399.0,利润为108601.0\n",
      "第207次训练\n",
      "最优模型为35\n",
      "执行时间: 243.2067174911499 秒,60次未求解，当前强化学习值为-191443.0,利润为104257.0\n",
      "第208次训练\n",
      "最优模型为35\n",
      "执行时间: 244.13494753837585 秒,59次未求解，当前强化学习值为-161679.0,利润为129321.0\n",
      "第209次训练\n",
      "最优模型为35\n",
      "执行时间: 245.13988399505615 秒,51次未求解，当前强化学习值为23954.0,利润为286754.0\n",
      "第210次训练\n",
      "最优模型为35\n",
      "执行时间: 246.03105187416077 秒,60次未求解，当前强化学习值为-183013.0,利润为112087.0\n",
      "第211次训练\n",
      "最优模型为35\n",
      "执行时间: 247.0749294757843 秒,48次未求解，当前强化学习值为76701.0,利润为330601.0\n",
      "第212次训练\n",
      "最优模型为35\n",
      "执行时间: 248.1468517780304 秒,49次未求解，当前强化学习值为59010.0,利润为318010.0\n",
      "第213次训练\n",
      "最优模型为35\n",
      "执行时间: 249.4684054851532 秒,41次未求解，当前强化学习值为202808.0,利润为437508.0\n",
      "第214次训练\n",
      "最优模型为35\n",
      "执行时间: 250.35275077819824 秒,60次未求解，当前强化学习值为-189198.0,利润为108602.0\n",
      "第215次训练\n",
      "最优模型为35\n",
      "执行时间: 252.0311381816864 秒,24次未求解，当前强化学习值为648412.0,利润为803012.0\n",
      "第216次训练\n",
      "最优模型为35\n",
      "执行时间: 253.1603446006775 秒,51次未求解，当前强化学习值为48759.0,利润为307659.0\n",
      "第217次训练\n",
      "最优模型为35\n",
      "执行时间: 254.5544149875641 秒,40次未求解，当前强化学习值为270620.0,利润为488320.0\n",
      "第218次训练\n",
      "最优模型为35\n",
      "执行时间: 255.55295395851135 秒,59次未求解，当前强化学习值为-163656.0,利润为127244.0\n",
      "第219次训练\n",
      "最优模型为35\n",
      "执行时间: 256.5672302246094 秒,58次未求解，当前强化学习值为-140753.0,利润为149647.0\n",
      "第220次训练\n",
      "最优模型为35\n",
      "执行时间: 257.70841789245605 秒,48次未求解，当前强化学习值为73917.0,利润为328117.0\n",
      "第221次训练\n",
      "最优模型为35\n",
      "执行时间: 258.69633173942566 秒,59次未求解，当前强化学习值为-163358.0,利润为127242.0\n",
      "第222次训练\n",
      "最优模型为35\n",
      "执行时间: 260.21940994262695 秒,43次未求解，当前强化学习值为198826.0,利润为425426.0\n",
      "第223次训练\n",
      "最优模型为35\n",
      "执行时间: 261.903112411499 秒,33次未求解，当前强化学习值为405308.0,利润为600808.0\n",
      "第224次训练\n",
      "最优模型为35\n",
      "执行时间: 262.8095097541809 秒,60次未求解，当前强化学习值为-185625.0,利润为108375.0\n",
      "第225次训练\n",
      "最优模型为35\n",
      "执行时间: 263.83556151390076 秒,57次未求解，当前强化学习值为-123961.0,利润为163339.0\n",
      "第226次训练\n",
      "最优模型为35\n",
      "执行时间: 265.05682849884033 秒,51次未求解，当前强化学习值为40659.0,利润为299259.0\n",
      "第227次训练\n",
      "最优模型为35\n",
      "执行时间: 265.98778200149536 秒,60次未求解，当前强化学习值为-182715.0,利润为112085.0\n",
      "第228次训练\n",
      "最优模型为35\n",
      "执行时间: 267.057181596756 秒,55次未求解，当前强化学习值为-48599.0,利润为218201.0\n",
      "第229次训练\n",
      "最优模型为35\n",
      "执行时间: 267.9928729534149 秒,60次未求解，当前强化学习值为-194184.0,利润为105716.0\n",
      "第230次训练\n",
      "最优模型为35\n",
      "执行时间: 268.964234828949 秒,60次未求解，当前强化学习值为-187866.0,利润为107834.0\n",
      "第231次训练\n",
      "最优模型为35\n",
      "执行时间: 269.9218215942383 秒,60次未求解，当前强化学习值为-193943.0,利润为104257.0\n",
      "第232次训练\n",
      "最优模型为35\n",
      "执行时间: 270.89600133895874 秒,60次未求解，当前强化学习值为-191198.0,利润为108602.0\n",
      "第233次训练\n",
      "最优模型为35\n",
      "执行时间: 272.1765356063843 秒,48次未求解，当前强化学习值为79180.0,利润为333880.0\n",
      "第234次训练\n",
      "最优模型为35\n",
      "执行时间: 273.50864362716675 秒,47次未求解，当前强化学习值为109717.0,利润为353317.0\n",
      "第235次训练\n",
      "最优模型为35\n",
      "执行时间: 274.6288814544678 秒,54次未求解，当前强化学习值为-55096.0,利润为221304.0\n",
      "第236次训练\n",
      "最优模型为35\n",
      "执行时间: 275.55756282806396 秒,60次未求解，当前强化学习值为-181387.0,利润为112313.0\n",
      "第237次训练\n",
      "最优模型为35\n",
      "执行时间: 276.5299873352051 秒,60次未求解，当前强化学习值为-185989.0,利润为112311.0\n",
      "第238次训练\n",
      "最优模型为35\n",
      "执行时间: 277.5316972732544 秒,60次未求解，当前强化学习值为-186115.0,利润为112085.0\n",
      "第239次训练\n",
      "最优模型为35\n",
      "执行时间: 278.9533004760742 秒,42次未求解，当前强化学习值为211392.0,利润为440392.0\n",
      "第240次训练\n",
      "最优模型为35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 151\u001b[0m\n\u001b[0;32m    149\u001b[0m     next_order_states \u001b[38;5;241m=\u001b[39m vectorization_order(orders_unmatched)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# 这里防止梯度爆炸缩小了reward\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvehicle_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mgrid_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_vehicle_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_order_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     env\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m=\u001b[39m time\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n",
      "File \u001b[1;32md:\\mycodelife\\workshop\\DRL_CO\\multiagent.py:167\u001b[0m, in \u001b[0;36mMultiAgentAC.update\u001b[1;34m(self, vehicle_states, order_states, actions, rewards, next_vehicle_states, next_order_states, dones)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 167\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from gurobipy import *\n",
    "from CITY_GRAPH import *\n",
    "from CITY_NODE import *\n",
    "from ORDER import *\n",
    "from VEHICLE import *\n",
    "from tool_func import *\n",
    "from Lower_Layer import *\n",
    "import SETTING\n",
    "import importlib\n",
    "import tool_func\n",
    "from update import *\n",
    "import os\n",
    "import time as tm\n",
    "import copy\n",
    "from my_env import *\n",
    "import torch\n",
    "import multiagent as magent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"这里是非强化学习部分\"\"\"\n",
    "# 初始化\n",
    "num_vehicle = 20\n",
    "num_order = 6\n",
    "num_city = 8\n",
    "TIME = 144  # \n",
    "CAPACITY = 7\n",
    "row = [10, 1, 3, 10]\n",
    "Vehicles = {}\n",
    "speed = 20 # 之前是20\n",
    "cancel_penalty = 300\n",
    "battery_consume = 10\n",
    "battery_add = 300\n",
    "\n",
    "matrix = np.tile(row, (num_vehicle, 1))\n",
    "\n",
    "# 初始化\n",
    "Vehicles = vehicle_generator(num_vehicle, num_city)\n",
    "orders_unmatched = {}\n",
    "G = CityGraph(num_city, 0.3, (10, 30))\n",
    "name = \"navie\"\n",
    "cancel_penalty = 300\n",
    "order_canceled = 0\n",
    "Total_order = {}\n",
    "\n",
    "# 设置s_0\n",
    "for time in range(TIME):\n",
    "    Orders = order_generator(num_order, time, num_city-1, CAPACITY, G ,speed)\n",
    "    for order in Orders.values():\n",
    "        Total_order[order.id] = order\n",
    "\n",
    "# 深复制最初的订单与车辆\n",
    "prim_order = copy.deepcopy(Total_order)\n",
    "prim_vehicle = copy.deepcopy(Vehicles)\n",
    "\"\"\"这里是强化学习部分\"\"\"\n",
    "# 超参数\n",
    "STATE_DIM_VEHICLE = 11   # 车辆状态的特征维度\n",
    "STATE_DIM_ORDER = 12     # 订单状态的特征维度\n",
    "HIDDEN_DIM = 128         # 隐藏层维度\n",
    "ACTION_DIM = num_city          # 动作空间维度\n",
    "ACTOR_LR = 1e-2          # Actor 学习率\n",
    "CRITIC_LR = 1e-2         # Critic 学习率\n",
    "GAMMA = 0.99             # 折扣因子\n",
    "NUM_EPISODES = 300     # 总训练轮数\n",
    "# 这里也改了\n",
    "STATE_DIM = 2 *HIDDEN_DIM       \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = magent.MultiAgentAC(\n",
    "    device = DEVICE,\n",
    "    VEHICLE_STATE_DIM = STATE_DIM_VEHICLE,\n",
    "    ORDER_STATE_DIM = STATE_DIM_ORDER, \n",
    "    NUM_CITIES = num_city, \n",
    "    HIDDEN_DIM = HIDDEN_DIM, \n",
    "    STATE_DIM = STATE_DIM\n",
    ")\n",
    "print(type(agent))\n",
    "grid_rewards = []\n",
    "# 开始计时\n",
    "start_time = tm.time()\n",
    "\n",
    "episode_reward = 0\n",
    "ACTIONS = []\n",
    "base_revenue = []\n",
    "first_revnue = []\n",
    "base_vehicle = []\n",
    "base_vehicle_class = []\n",
    "base_order_class = []\n",
    "base_city_node = []\n",
    "train_rewards = []\n",
    "burn_in = 100\n",
    "batch_time = int(TIME/2)\n",
    "for episode in range(NUM_EPISODES):\n",
    "    print(f\"第{episode}次训练\")\n",
    "    Total_order = copy.deepcopy(prim_order)\n",
    "    Vehicles = copy.deepcopy(prim_vehicle)\n",
    "    objval = 0\n",
    "    total_objval = 0\n",
    "    reward = 0\n",
    "    episode_reward = 0\n",
    "    invalid_time =  0\n",
    "    orders_unmatched = {} # 忘记加这个了\n",
    "    orders_virtual = {}\n",
    "    \n",
    "    if episode > 0:\n",
    "        # agent.load_model(load_path)\n",
    "        if episode > 1:\n",
    "            env.time = 0\n",
    "        \n",
    "        if episode < burn_in:\n",
    "            greedy_epsilon = 0.6\n",
    "            explore = True\n",
    "        else:\n",
    "            greedy_epsilon = 0.001\n",
    "            explore = False\n",
    "            if episode == burn_in:\n",
    "                best_model = train_rewards.index(max(train_rewards))\n",
    "                agent = torch.load(f'model_checkpoint_{best_model+1}.pth',map_location=\"cpu\")\n",
    "                print(f\"最优模型为{best_model}\")\n",
    "                agent.eval()\n",
    "            if episode > burn_in:\n",
    "                if train_rewards[best_model] > train_rewards[-1] or first_invalid >= invalid_time:\n",
    "                    agent = torch.load(f'model_checkpoint_{best_model+1}.pth',map_location=\"cpu\")\n",
    "                    print(f\"最优模型为{best_model}\")\n",
    "                    agent.eval()\n",
    "                else:\n",
    "                    best_model = train_rewards.index(train_rewards[-1]) \n",
    "                    agent = torch.load(f'model_checkpoint_{best_model+1}.pth',map_location=\"cpu\")\n",
    "                    print(f\"最优模型为{best_model}\")\n",
    "                    agent.eval()\n",
    "    if_end = False\n",
    "    for time in range(batch_time):\n",
    "    \n",
    "        group = [[], []]\n",
    "        if time == batch_time -1:\n",
    "            if_end = True\n",
    "        # 按时间给出订单\n",
    "        for order in Total_order.values():\n",
    "            if order.start_time == time:\n",
    "                orders_unmatched[order.id] = order\n",
    "            # 加上这个代码后会导致性能降低\n",
    "            \"\"\"\n",
    "            if order.matched is False:\n",
    "                order.virtual_departure = order.departure \n",
    "            \"\"\"\n",
    "        if time != 0 and episode != 0:\n",
    "            next_vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 改了，不再是total_order\n",
    "            next_order_states = vectorization_order(orders_unmatched)\n",
    "            # 这里防止梯度爆炸缩小了reward\n",
    "            agent.update(vehicle_states, order_states, action,\n",
    "                         grid_reward, next_vehicle_states, next_order_states , if_end)\n",
    "            env.time = time\n",
    "        if time == 0 :\n",
    "            orders_virtual = orders_unmatched\n",
    "           \n",
    "            city_node = city_node_generator(G, orders_virtual, Vehicles, orders_unmatched)\n",
    "            if episode == 1 :\n",
    "                env = DispatchEnv(\n",
    "                    G=G,\n",
    "                    vehicles=Vehicles,\n",
    "                    orders=Total_order,\n",
    "                    cities=city_node,\n",
    "                    capacity=CAPACITY\n",
    "                )\n",
    "            elif episode > 1:\n",
    "                env.cities = city_node\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            if episode == 0:\n",
    "                city_update_without_drl(city_node , Vehicles, orders_unmatched ,time)\n",
    "            else:\n",
    "                city_update_without_drl(env.cities , Vehicles, orders_unmatched, time)\n",
    "            \n",
    "        if episode != 0:\n",
    "            \n",
    "            vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 这里也改了\n",
    "            order_states = vectorization_order(orders_unmatched)\n",
    "            \n",
    "            greedy = random.randint(0, 1)\n",
    "            if greedy > greedy_epsilon:\n",
    "                greedy = True\n",
    "            action = agent.take_action(vehicle_states, order_states, explore, greedy)\n",
    "            reward = env.test_step(orders_unmatched,action)\n",
    "            # 一个循环代码让我达到最优\n",
    "            # 屁股后面的代码是为了让我达到最优\n",
    "            # 这里是为了让我达到最优\n",
    "            # 现在放弃了重采样\n",
    "            \"\"\"\n",
    "            COUNT = 1000\n",
    "            max_reward = -999999\n",
    "            max_action = action\n",
    "            \n",
    "           \n",
    "            while reward != 1000 and COUNT > 0:\n",
    "                greedy = random.randint(0, 1)\n",
    "                if greedy > greedy_epsilon:\n",
    "                    greedy = True\n",
    "                action = agent.take_action(vehicle_states, order_states, explore, greedy)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "                COUNT -= 1\n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    max_action = action\n",
    "            if COUNT == 0:\n",
    "                reward = env.test_step(orders_unmatched, max_action)\n",
    "            \"\"\"\n",
    "            \n",
    "           \n",
    "            \n",
    "            ACTIONS.append(action) \n",
    "            \"\"\"\n",
    "            while reward != 0 :\n",
    "                action = agent.take_action(vehicle_states, order_states)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "        for vehicle in Vehicles.values():\n",
    "            if vehicle.whether_city:\n",
    "                group[0].append(vehicle.id)\n",
    "            else:\n",
    "                group[1].append(vehicle.id)\n",
    "\n",
    "        if len(group[0]) != 0:\n",
    "\n",
    "            if episode == 0:\n",
    "                temp_Lower_Layer = Lower_Layer(G, city_node, Vehicles, orders_unmatched, name, group, time)\n",
    "            else:\n",
    "                temp_Lower_Layer = Lower_Layer(G, env.cities, Vehicles, orders_unmatched, name, group, time)\n",
    "            try:\n",
    "                temp_Lower_Layer.get_decision()\n",
    "                temp_Lower_Layer.constrain_1()\n",
    "                temp_Lower_Layer.constrain_2()\n",
    "                temp_Lower_Layer.constrain_3()\n",
    "                temp_Lower_Layer.constrain_4()\n",
    "                temp_Lower_Layer.constrain_5()\n",
    "                temp_Lower_Layer.model.setParam('OutputFlag', 0)\n",
    "                total_penalty = cancel_penalty * order_canceled\n",
    "                temp_Lower_Layer.set_objective(matrix)\n",
    "            \n",
    "                temp_Lower_Layer.model.optimize()\n",
    "\n",
    "                if temp_Lower_Layer.model.status == GRB.OPTIMAL:\n",
    "                    # save_results(temp_Lower_Layer,time)\n",
    "                    # print(\"Objective value:\", temp_Lower_Layer.model.objVal)\n",
    "                    objval = temp_Lower_Layer.model.objVal \n",
    "                else:\n",
    "                    temp_Lower_Layer.model.computeIIS()\n",
    "                    temp_Lower_Layer.model.write('iis.ilp')  # 保存不可行约束\n",
    "                    # print(f\"{time}次，No optimal solution found.\")\n",
    "                    self_update(Vehicles, G)\n",
    "                    objval = basic_cost(Vehicles, orders_unmatched)\n",
    "                    \n",
    "                \n",
    "                _, var_order = temp_Lower_Layer.get_decision()\n",
    "                update_var(temp_Lower_Layer, Vehicles, orders_unmatched)\n",
    "                vehicle_in_city = update_vehicle(Vehicles, battery_consume, battery_add, speed, G)\n",
    "                order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            except:\n",
    "                self_update(Vehicles, G)\n",
    "               \n",
    "                order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "                objval = - basic_cost(Vehicles, orders_unmatched)\n",
    "                invalid_time += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self_update(Vehicles, G)\n",
    "            # print(f\"{episode}轮，{time}次，{len(group[1])}辆车不在城市\")\n",
    "            order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            objval = - basic_cost(Vehicles, orders_unmatched)\n",
    "            # 利润（如果有）减去新增的取消订单\n",
    "            \n",
    "            invalid_time += 1\n",
    "        objval = objval - update_order(orders_unmatched, time, speed) * cancel_penalty\n",
    "        if episode != 0: \n",
    "            \n",
    "            # 防止梯度爆炸\n",
    "            grid_reward =   objval\n",
    "            grid_rewards.append(reward)\n",
    "            # print(grid_reward)\n",
    "            episode_reward += reward + objval\n",
    "        total_objval += objval\n",
    "\n",
    "        if episode == 0:\n",
    "            base_revenue.append(objval)\n",
    "            base_vehicle.append(copy.deepcopy(group[0]))\n",
    "            # base_vehicle_class.append(copy.deepcopy(Vehicles))\n",
    "            # base_order_class.append(copy.deepcopy(Total_order))\n",
    "            \n",
    "            base_city_node.append(copy.deepcopy(city_node))\n",
    "            \"\"\"\n",
    "            if episode == 1:\n",
    "                first_revnue.append(objval)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # if base_revenue[time] != objval:\n",
    "            #    print(\"base_revenue\",time, objval,base_revenue[time])\n",
    "            # if first_revnue[time] != objval:\n",
    "            #    print(\"first_revenue\",time, first_revnue[time], objval)\n",
    "            \"\"\" \n",
    "            if base_vehicle[time] != group[0]:\n",
    "                print(\"vehicle is different\", len(base_vehicle[time]), len(group[0]))\n",
    "            if base_city_node[time] != env.cities:\n",
    "                print(time, base_city_node[time],\"\\n\", env.cities)\n",
    "            \"\"\"\n",
    "            \n",
    "        # print(f\"{len(orders_unmatched)}订单未被匹配,{order_canceled}订单超时,总利润为{objval},强化学习利润为{reward}\")\n",
    "    end_time = tm.time()\n",
    "    execution_time = end_time - start_time\n",
    "    if episode != 0:\n",
    "        print(f\"执行时间: {execution_time} 秒,{invalid_time}次未求解，当前强化学习值为{episode_reward},利润为{total_objval}\")\n",
    "        # torch.save(agent.state_dict(), 'model_checkpoint.pth')\n",
    "        torch.save(agent, f\"model_checkpoint_{episode}.pth\")\n",
    "        train_rewards.append(total_objval)\n",
    "        first_invalid = invalid_time\n",
    "    else:\n",
    "        print(f\"未加强化学习利润为{total_objval},{invalid_time}次未求解\")\n",
    "    # grid_rewards.append(0)\n",
    "    # save_path = f\"actor_critic_model{episode}.pth\"\n",
    "    # load_path = f\"actor_critic_model{episode}.pth\"\n",
    "    \n",
    "plt.plot(grid_rewards, label='Grid Reward Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Grid Reward')\n",
    "plt.title('Reward Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# print(find_duplicates_with_positions(ACTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:alns.ALNS:Finished iterating in 0.15s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best routes: [[0, 1, 0], [0, 2, 0], [0, 3, 0], [0, 4, 0], [0, 5, 0], [0, 6, 0], [0, 7, 0], [0, 8, 0], [0, 9, 0], [0, 10, 0]]\n",
      "Best cost: 858.1198159028768\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from alns import ALNS, State\n",
    "from alns.accept import SimulatedAnnealing\n",
    "from alns.stop import MaxIterations\n",
    "from alns.select import RouletteWheel\n",
    "import random\n",
    "\n",
    "# Problem Data\n",
    "np.random.seed(42)\n",
    "num_customers = 10\n",
    "num_vehicles = 3\n",
    "capacity = 100\n",
    "\n",
    "# 随机生成坐标和需求\n",
    "depot = np.array([50, 50])\n",
    "nodes = np.random.randint(0, 100, (num_customers, 2))\n",
    "demands = np.random.randint(5, 20, num_customers)\n",
    "\n",
    "# 计算欧几里得距离\n",
    "def distance(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "distance_matrix = np.zeros((num_customers + 1, num_customers + 1))\n",
    "nodes_full = np.vstack([depot, nodes])  # 加入仓库\n",
    "for i in range(len(nodes_full)):\n",
    "    for j in range(len(nodes_full)):\n",
    "        distance_matrix[i, j] = distance(nodes_full[i], nodes_full[j])\n",
    "\n",
    "# 初始状态\n",
    "class VRPState(State):\n",
    "    def __init__(self, routes):\n",
    "        self.routes = routes\n",
    "    \n",
    "    def objective(self):\n",
    "        total_cost = sum(\n",
    "            distance_matrix[route[i], route[i+1]]\n",
    "            for route in self.routes for i in range(len(route)-1)\n",
    "        )\n",
    "        return total_cost\n",
    "    \n",
    "    def copy(self):\n",
    "        return VRPState([route[:] for route in self.routes])\n",
    "\n",
    "# 破坏算子\n",
    "def random_removal(state, rng, num_remove=2):\n",
    "    if isinstance(num_remove, np.random.Generator):  \n",
    "        num_remove = rng.integers(1, 4)  \n",
    "\n",
    "    new_state = state.copy()\n",
    "    for _ in range(num_remove):\n",
    "        if any(new_state.routes):\n",
    "            route = random.choice(new_state.routes)\n",
    "            if len(route) > 2:  # 只有在长度 > 2 时才移除\n",
    "                idx = rng.integers(1, max(2, len(route) - 1))  # 确保 idx 合法\n",
    "                route.pop(idx)\n",
    "    return new_state\n",
    "\n",
    "\n",
    "\n",
    "# 修复算子\n",
    "def greedy_insert(state, rng):\n",
    "    new_state = state.copy()\n",
    "    unassigned = [i for i in range(1, num_customers + 1) if not any(i in r for r in new_state.routes)]\n",
    "    for i in unassigned:\n",
    "        best_cost = float('inf')\n",
    "        best_route = None\n",
    "        best_position = None\n",
    "        for route in new_state.routes:\n",
    "            for pos in range(1, len(route)):\n",
    "                temp_route = route[:pos] + [i] + route[pos:]\n",
    "                cost = sum(distance_matrix[temp_route[j], temp_route[j+1]] for j in range(len(temp_route)-1))\n",
    "                if cost < best_cost:\n",
    "                    best_cost, best_route, best_position = cost, route, pos\n",
    "        if best_route is not None:\n",
    "            best_route.insert(best_position, i)\n",
    "    return new_state\n",
    "\n",
    "# ALNS 运行\n",
    "initial_routes = [[0, i, 0] for i in range(1, num_customers + 1)]  # 每个客户单独一辆车\n",
    "initial_state = VRPState(initial_routes)\n",
    "alns = ALNS()\n",
    "alns.add_destroy_operator(random_removal)\n",
    "alns.add_repair_operator(greedy_insert)\n",
    "\n",
    "# 设定接受准则（模拟退火）\n",
    "accept = SimulatedAnnealing(1000, 1, 500, method=\"linear\")\n",
    "select = RouletteWheel([1] * 4, 0.8, 1, 1)\n",
    "stop = MaxIterations(1000)\n",
    "\n",
    "result = alns.iterate(initial_state, select, accept, stop)\n",
    "\n",
    "# 输出最优解\n",
    "best_state = result.best_state\n",
    "print(\"Best routes:\", best_state.routes)\n",
    "print(\"Best cost:\", best_state.objective())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
