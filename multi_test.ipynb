{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from gurobipy import *\n",
    "from CITY_GRAPH import *\n",
    "from CITY_NODE import *\n",
    "from ORDER import *\n",
    "from VEHICLE import *\n",
    "from tool_func import *\n",
    "from Lower_Layer import *\n",
    "import SETTING\n",
    "import importlib\n",
    "import tool_func\n",
    "from update import *\n",
    "import os\n",
    "import time as tm\n",
    "import copy\n",
    "from my_env import *\n",
    "import torch\n",
    "import multiagent as magent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"这里是非强化学习部分\"\"\"\n",
    "# 初始化\n",
    "num_vehicle = 50\n",
    "num_order = 10\n",
    "num_city = 8\n",
    "TIME = 144  # \n",
    "CAPACITY = 7\n",
    "row = [10, 1, 3, 10]\n",
    "Vehicles = {}\n",
    "speed = 20 # 之前是20\n",
    "cancel_penalty = 300\n",
    "battery_consume = 10\n",
    "battery_add = 300\n",
    "\n",
    "matrix = np.tile(row, (num_vehicle, 1))\n",
    "\n",
    "# 初始化\n",
    "Vehicles = vehicle_generator(num_vehicle, num_city)\n",
    "orders_unmatched = {}\n",
    "G = CityGraph(num_city, 0.3, (10, 30))\n",
    "name = \"navie\"\n",
    "cancel_penalty = 300\n",
    "order_canceled = 0\n",
    "Total_order = {}\n",
    "\n",
    "# 设置s_0\n",
    "for time in range(TIME):\n",
    "    Orders = order_generator(num_order, time, num_city-1, CAPACITY, G ,speed)\n",
    "    for order in Orders.values():\n",
    "        Total_order[order.id] = order\n",
    "\n",
    "# 深复制最初的订单与车辆\n",
    "prim_order = copy.deepcopy(Total_order)\n",
    "prim_vehicle = copy.deepcopy(Vehicles)\n",
    "\"\"\"这里是强化学习部分\"\"\"\n",
    "# 超参数\n",
    "STATE_DIM_VEHICLE = 11   # 车辆状态的特征维度\n",
    "STATE_DIM_ORDER = 12     # 订单状态的特征维度\n",
    "HIDDEN_DIM = 128         # 隐藏层维度\n",
    "ACTION_DIM = num_city          # 动作空间维度\n",
    "ACTOR_LR = 1e-2          # Actor 学习率\n",
    "CRITIC_LR = 1e-2         # Critic 学习率\n",
    "GAMMA = 0.99             # 折扣因子\n",
    "NUM_EPISODES = 100      # 总训练轮数\n",
    "# 这里也改了\n",
    "STATE_DIM = 2 *HIDDEN_DIM       \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = magent.MultiAgentAC(\n",
    "    device = DEVICE,\n",
    "    VEHICLE_STATE_DIM = STATE_DIM_VEHICLE,\n",
    "    ORDER_STATE_DIM = STATE_DIM_ORDER, \n",
    "    NUM_CITIES = num_city, \n",
    "    HIDDEN_DIM = HIDDEN_DIM, \n",
    "    STATE_DIM = STATE_DIM\n",
    ")\n",
    "grid_rewards = []\n",
    "# 开始计时\n",
    "start_time = tm.time()\n",
    "\n",
    "episode_reward = 0\n",
    "ACTIONS = []\n",
    "base_revenue = []\n",
    "first_revnue = []\n",
    "base_vehicle = []\n",
    "base_vehicle_class = []\n",
    "base_order_class = []\n",
    "base_city_node = []\n",
    "for episode in range(NUM_EPISODES):\n",
    "    print(f\"第{episode}次训练\")\n",
    "    Total_order = copy.deepcopy(prim_order)\n",
    "    Vehicles = copy.deepcopy(prim_vehicle)\n",
    "    objval = 0\n",
    "    total_objval = 0\n",
    "    reward = 0\n",
    "    episode_reward = 0\n",
    "    invalid_time =  0\n",
    "    orders_unmatched = {} # 忘记加这个了\n",
    "    orders_virtual = {}\n",
    "    \n",
    "    if episode > 1:\n",
    "        # agent.load_model(load_path)\n",
    "        env.time = 0\n",
    "\n",
    "    for time in range(TIME):\n",
    "    \n",
    "        group = [[], []]\n",
    "\n",
    "        # 按时间给出订单\n",
    "        for order in Total_order.values():\n",
    "            if order.start_time == time:\n",
    "                orders_unmatched[order.id] = order\n",
    "            # 加上这个代码后会导致性能降低\n",
    "            \"\"\"\n",
    "            if order.matched is False:\n",
    "                order.virtual_departure = order.departure \n",
    "            \"\"\"\n",
    "        if time != 0 and episode != 0:\n",
    "            next_vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 改了，不再是total_order\n",
    "            next_order_states = vectorization_order(orders_unmatched)\n",
    "            # 这里防止梯度爆炸缩小了reward\n",
    "            agent.update(vehicle_states, order_states, grid_reward, next_vehicle_states, next_order_states, True ,action)\n",
    "            env.time = time\n",
    "        if time == 0 :\n",
    "            orders_virtual = orders_unmatched\n",
    "           \n",
    "            city_node = city_node_generator(G, orders_virtual, Vehicles, orders_unmatched)\n",
    "            if episode == 1 :\n",
    "                env = DispatchEnv(\n",
    "                    G=G,\n",
    "                    vehicles=Vehicles,\n",
    "                    orders=Total_order,\n",
    "                    cities=city_node,\n",
    "                    capacity=CAPACITY\n",
    "                )\n",
    "            elif episode > 1:\n",
    "                env.cities = city_node\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            if episode == 0:\n",
    "                city_update_without_drl(city_node , Vehicles, orders_unmatched ,time)\n",
    "            else:\n",
    "                city_update_without_drl(env.cities , Vehicles, orders_unmatched, time)\n",
    "            \n",
    "        if episode != 0:\n",
    "            \n",
    "            vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 这里也改了\n",
    "            order_states = vectorization_order(orders_unmatched)\n",
    "            \n",
    "            action = agent.take_action(vehicle_states, order_states)\n",
    "        \n",
    "            ACTIONS.append(action)            \n",
    "            reward = env.test_step(orders_unmatched,action)\n",
    "            # 一个循环代码让我达到最优\n",
    "            # 屁股后面的代码是为了让我达到最优\n",
    "            # 这里是为了让我达到最优\n",
    "           \n",
    "            change_time = 0\n",
    "            COUNT = 999\n",
    "            min_reward = -999999\n",
    "            min_action = action\n",
    "            while reward != 0 and COUNT > 0:\n",
    "                action = agent.take_action(vehicle_states, order_states)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "                COUNT -= 1\n",
    "                if reward > min_reward:\n",
    "                    min_reward = reward\n",
    "                    min_action = action\n",
    "            if COUNT == 0:\n",
    "                reward = env.test_step(orders_unmatched,min_action)\n",
    "            \n",
    "            \"\"\"\n",
    "            COUNT = 999\n",
    "            min_reward = -999999\n",
    "            min_action = action\n",
    "            while reward != 0 and COUNT > 0:\n",
    "                action = agent.take_action(vehicle_states, order_states)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "                COUNT -= 1\n",
    "                if reward > min_reward:\n",
    "                    min_reward = reward\n",
    "                    min_action = action\n",
    "            if COUNT == 0:\n",
    "                reward = env.test_step(orders_unmatched,min_action)\n",
    "            for env_order in env.orders.values():\n",
    "                for order_unmatched in orders_unmatched.values():\n",
    "                    if env_order.id == order_unmatched.id:\n",
    "                        order_unmatched.virtual_departure = env_order.virtual_departure\n",
    "                        change_time += 1\n",
    "            print(change_time)\n",
    "            city_update_base_drl(env.cities, orders_unmatched ,time)\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "        for vehicle in Vehicles.values():\n",
    "            if vehicle.whether_city:\n",
    "                group[0].append(vehicle.id)\n",
    "            else:\n",
    "                group[1].append(vehicle.id)\n",
    "\n",
    "        if len(group[0]) != 0:\n",
    "            if episode == 0:\n",
    "                temp_Lower_Layer = Lower_Layer(G, city_node, Vehicles, orders_unmatched, name, group, time)\n",
    "            else:\n",
    "                temp_Lower_Layer = Lower_Layer(G, env.cities, Vehicles, orders_unmatched, name, group, time)\n",
    "            temp_Lower_Layer.get_decision()\n",
    "            temp_Lower_Layer.constrain_1()\n",
    "            temp_Lower_Layer.constrain_2()\n",
    "            temp_Lower_Layer.constrain_3()\n",
    "            temp_Lower_Layer.constrain_4()\n",
    "            temp_Lower_Layer.constrain_5()\n",
    "            temp_Lower_Layer.model.setParam('OutputFlag', 0)\n",
    "            total_penalty = cancel_penalty * order_canceled\n",
    "            temp_Lower_Layer.set_objective(matrix)\n",
    "        \n",
    "            temp_Lower_Layer.model.optimize()\n",
    "\n",
    "            if temp_Lower_Layer.model.status == GRB.OPTIMAL:\n",
    "                # save_results(temp_Lower_Layer,time)\n",
    "                # print(\"Objective value:\", temp_Lower_Layer.model.objVal)\n",
    "                objval = temp_Lower_Layer.model.objVal \n",
    "            else:\n",
    "                temp_Lower_Layer.model.computeIIS()\n",
    "                temp_Lower_Layer.model.write('iis.ilp')  # 保存不可行约束\n",
    "                # print(f\"{time}次，No optimal solution found.\")\n",
    "                self_update(Vehicles, G)\n",
    "                objval = basic_cost(Vehicles, orders_unmatched)\n",
    "                \n",
    "            \n",
    "            _, var_order = temp_Lower_Layer.get_decision()\n",
    "            update_var(temp_Lower_Layer, Vehicles, orders_unmatched)\n",
    "            vehicle_in_city = update_vehicle(Vehicles, battery_consume, battery_add, speed, G)\n",
    "            order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self_update(Vehicles, G)\n",
    "            # print(f\"{episode}轮，{time}次，{len(group[1])}辆车不在城市\")\n",
    "            order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            objval = basic_cost(Vehicles, orders_unmatched)\n",
    "            # 利润（如果有）减去新增的取消订单\n",
    "            \n",
    "            invalid_time += 1\n",
    "        objval = objval - update_order(orders_unmatched, time, speed) * cancel_penalty\n",
    "        if episode != 0: \n",
    "            \n",
    "            # 防止梯度爆炸\n",
    "            grid_reward =  objval + reward\n",
    "            grid_rewards.append(grid_reward)\n",
    "            # print(grid_reward)\n",
    "            episode_reward += reward + objval\n",
    "        total_objval += objval\n",
    "\n",
    "        if episode == 0:\n",
    "            base_revenue.append(objval)\n",
    "            base_vehicle.append(copy.deepcopy(group[0]))\n",
    "            # base_vehicle_class.append(copy.deepcopy(Vehicles))\n",
    "            # base_order_class.append(copy.deepcopy(Total_order))\n",
    "            \n",
    "            base_city_node.append(copy.deepcopy(city_node))\n",
    "            \"\"\"\n",
    "            if episode == 1:\n",
    "                first_revnue.append(objval)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # if base_revenue[time] != objval:\n",
    "            #    print(\"base_revenue\",time, objval,base_revenue[time])\n",
    "            # if first_revnue[time] != objval:\n",
    "            #    print(\"first_revenue\",time, first_revnue[time], objval)\n",
    "            \"\"\" \n",
    "            if base_vehicle[time] != group[0]:\n",
    "                print(\"vehicle is different\", len(base_vehicle[time]), len(group[0]))\n",
    "            if base_city_node[time] != env.cities:\n",
    "                print(time, base_city_node[time],\"\\n\", env.cities)\n",
    "            \"\"\"\n",
    "            \n",
    "        # print(f\"{len(orders_unmatched)}订单未被匹配,{order_canceled}订单超时,总利润为{objval},强化学习利润为{reward}\")\n",
    "    end_time = tm.time()\n",
    "    execution_time = end_time - start_time\n",
    "    if episode != 0:\n",
    "        print(f\"执行时间: {execution_time} 秒,{invalid_time}次未求解，当前强化学习值为{episode_reward},利润为{total_objval}\")\n",
    "        # torch.save(agent.state_dict(), 'model_checkpoint.pth')\n",
    "    else:\n",
    "        print(f\"未加强化学习利润为{total_objval},{invalid_time}次未求解\")\n",
    "    # grid_rewards.append(0)\n",
    "    # save_path = f\"actor_critic_model{episode}.pth\"\n",
    "    # load_path = f\"actor_critic_model{episode}.pth\"\n",
    "    # agent.save_model(save_path)\n",
    "plt.plot(grid_rewards, label='Grid Reward Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Grid Reward')\n",
    "plt.title('Reward Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# print(find_duplicates_with_positions(ACTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动态订单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from gurobipy import *\n",
    "from CITY_GRAPH import *\n",
    "from CITY_NODE import *\n",
    "from ORDER import *\n",
    "from VEHICLE import *\n",
    "from tool_func import *\n",
    "from Lower_Layer import *\n",
    "import SETTING\n",
    "import importlib\n",
    "import tool_func\n",
    "from update import *\n",
    "import os\n",
    "import time as tm\n",
    "import copy\n",
    "from my_env import *\n",
    "import torch\n",
    "import dynamic_multiagent as dm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"这里是非强化学习部分\"\"\"\n",
    "# 初始化\n",
    "num_vehicle = 50\n",
    "num_order = 10\n",
    "num_city = 8\n",
    "TIME = 144  # \n",
    "CAPACITY = 7\n",
    "row = [10, 1, 3, 10]\n",
    "Vehicles = {}\n",
    "speed = 20 # 之前是20\n",
    "cancel_penalty = 300\n",
    "battery_consume = 10\n",
    "battery_add = 300\n",
    "\n",
    "matrix = np.tile(row, (num_vehicle, 1))\n",
    "\n",
    "# 初始化\n",
    "Vehicles = vehicle_generator(num_vehicle, num_city)\n",
    "orders_unmatched = {}\n",
    "G = CityGraph(num_city, 0.3, (10, 30))\n",
    "name = \"navie\"\n",
    "cancel_penalty = 300\n",
    "order_canceled = 0\n",
    "Total_order = {}\n",
    "\n",
    "# 设置s_0\n",
    "for time in range(TIME):\n",
    "    Orders = order_generator(num_order, time, num_city-1, CAPACITY, G ,speed)\n",
    "    for order in Orders.values():\n",
    "        Total_order[order.id] = order\n",
    "\n",
    "# 深复制最初的订单与车辆\n",
    "prim_order = copy.deepcopy(Total_order)\n",
    "prim_vehicle = copy.deepcopy(Vehicles)\n",
    "\"\"\"这里是强化学习部分\"\"\"\n",
    "# 超参数\n",
    "STATE_DIM_VEHICLE = 11   # 车辆状态的特征维度\n",
    "STATE_DIM_ORDER = 12     # 订单状态的特征维度\n",
    "HIDDEN_DIM = 128         # 隐藏层维度\n",
    "ACTION_DIM = num_city          # 动作空间维度\n",
    "ACTOR_LR = 1e-2          # Actor 学习率\n",
    "CRITIC_LR = 1e-2         # Critic 学习率\n",
    "GAMMA = 0.99             # 折扣因子\n",
    "NUM_EPISODES = 100      # 总训练轮数\n",
    "# 这里也改了\n",
    "STATE_DIM = 2 *HIDDEN_DIM       \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = dm.DynamicMultiAgentAC(\n",
    "    device = DEVICE,\n",
    "    vehicle_state_dim =  STATE_DIM_VEHICLE,\n",
    "    order_state_dim = STATE_DIM_ORDER, \n",
    "    num_cities = num_city, \n",
    "    hidden_dim = HIDDEN_DIM, \n",
    ")\n",
    "grid_rewards = []\n",
    "# 开始计时\n",
    "start_time = tm.time()\n",
    "\n",
    "episode_reward = 0\n",
    "ACTIONS = []\n",
    "base_revenue = []\n",
    "first_revnue = []\n",
    "base_vehicle = []\n",
    "base_vehicle_class = []\n",
    "base_order_class = []\n",
    "base_city_node = []\n",
    "for episode in range(NUM_EPISODES):\n",
    "    print(f\"第{episode}次训练\")\n",
    "    Total_order = copy.deepcopy(prim_order)\n",
    "    Vehicles = copy.deepcopy(prim_vehicle)\n",
    "    agent.total_orders = Total_order\n",
    "    objval = 0\n",
    "    total_objval = 0\n",
    "    reward = 0\n",
    "    episode_reward = 0\n",
    "    invalid_time =  0\n",
    "    orders_unmatched = {} # 忘记加这个了\n",
    "    orders_virtual = {}\n",
    "    \n",
    "    if episode > 1:\n",
    "        # agent.load_model(load_path)\n",
    "        env.time = 0\n",
    "\n",
    "    for time in range(TIME):\n",
    "    \n",
    "        group = [[], []]\n",
    "\n",
    "        # 按时间给出订单\n",
    "        for order in Total_order.values():\n",
    "            if order.start_time == time:\n",
    "                orders_unmatched[order.id] = order\n",
    "            # 加上这个代码后会导致性能降低\n",
    "            \"\"\"\n",
    "            if order.matched is False:\n",
    "                order.virtual_departure = order.departure \n",
    "            \"\"\"\n",
    "        if time != 0 and episode != 0:\n",
    "            next_vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 改了，不再是total_order\n",
    "            next_order_states = vectorization_order(Total_order)\n",
    "            # 这里防止梯度爆炸缩小了reward\n",
    "            agent.update(vehicle_states, order_states, next_vehicle_states, next_order_states, action,grid_reward , mask)\n",
    "            env.time = time\n",
    "        if time == 0 :\n",
    "            orders_virtual = orders_unmatched\n",
    "           \n",
    "            city_node = city_node_generator(G, orders_virtual, Vehicles, orders_unmatched)\n",
    "            if episode == 1 :\n",
    "                env = DispatchEnv(\n",
    "                    G=G,\n",
    "                    vehicles=Vehicles,\n",
    "                    orders=Total_order,\n",
    "                    cities=city_node,\n",
    "                    capacity=CAPACITY\n",
    "                )\n",
    "            elif episode > 1:\n",
    "                env.cities = city_node\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            if episode == 0:\n",
    "                city_update_without_drl(city_node , Vehicles, orders_unmatched ,time)\n",
    "            else:\n",
    "                city_update_without_drl(env.cities , Vehicles, orders_unmatched, time)\n",
    "            \n",
    "        if episode != 0:\n",
    "            \n",
    "            vehicle_states = vectorization_vehicle(Vehicles)\n",
    "            # 这里也改了\n",
    "            order_states = vectorization_order(Total_order)\n",
    "            # 这里也加了\n",
    "            mask = agent.generate_mask()\n",
    "\n",
    "            action = agent.take_action(vehicle_states, order_states)\n",
    "\n",
    "            ACTIONS.append(action)            \n",
    "            reward = env.dynamic_step(Total_order,action,mask)\n",
    "            # 一个循环代码让我达到最优\n",
    "            # 屁股后面的代码是为了让我达到最优\n",
    "            # 这里是为了让我达到最优\n",
    "           \n",
    "            change_time = 0\n",
    "            COUNT = 999\n",
    "            min_reward = -999999\n",
    "            min_action = action\n",
    "            while reward != 0 and COUNT > 0:\n",
    "                action = agent.take_action(vehicle_states, order_states)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "                COUNT -= 1\n",
    "                if reward > min_reward:\n",
    "                    min_reward = reward\n",
    "                    min_action = action\n",
    "            if COUNT == 0:\n",
    "                reward = env.test_step(orders_unmatched,min_action)\n",
    "            \n",
    "            \"\"\"\n",
    "            COUNT = 999\n",
    "            min_reward = -999999\n",
    "            min_action = action\n",
    "            while reward != 0 and COUNT > 0:\n",
    "                action = agent.take_action(vehicle_states, order_states)\n",
    "                reward = env.test_step(orders_unmatched,action)\n",
    "                COUNT -= 1\n",
    "                if reward > min_reward:\n",
    "                    min_reward = reward\n",
    "                    min_action = action\n",
    "            if COUNT == 0:\n",
    "                reward = env.test_step(orders_unmatched,min_action)\n",
    "            for env_order in env.orders.values():\n",
    "                for order_unmatched in orders_unmatched.values():\n",
    "                    if env_order.id == order_unmatched.id:\n",
    "                        order_unmatched.virtual_departure = env_order.virtual_departure\n",
    "                        change_time += 1\n",
    "            print(change_time)\n",
    "            city_update_base_drl(env.cities, orders_unmatched ,time)\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "        for vehicle in Vehicles.values():\n",
    "            if vehicle.whether_city:\n",
    "                group[0].append(vehicle.id)\n",
    "            else:\n",
    "                group[1].append(vehicle.id)\n",
    "\n",
    "        if len(group[0]) != 0:\n",
    "            if episode == 0:\n",
    "                temp_Lower_Layer = Lower_Layer(G, city_node, Vehicles, orders_unmatched, name, group, time)\n",
    "            else:\n",
    "                temp_Lower_Layer = Lower_Layer(G, env.cities, Vehicles, orders_unmatched, name, group, time)\n",
    "            temp_Lower_Layer.get_decision()\n",
    "            temp_Lower_Layer.constrain_1()\n",
    "            temp_Lower_Layer.constrain_2()\n",
    "            temp_Lower_Layer.constrain_3()\n",
    "            temp_Lower_Layer.constrain_4()\n",
    "            temp_Lower_Layer.constrain_5()\n",
    "            temp_Lower_Layer.model.setParam('OutputFlag', 0)\n",
    "            total_penalty = cancel_penalty * order_canceled\n",
    "            temp_Lower_Layer.set_objective(matrix)\n",
    "        \n",
    "            temp_Lower_Layer.model.optimize()\n",
    "\n",
    "            if temp_Lower_Layer.model.status == GRB.OPTIMAL:\n",
    "                # save_results(temp_Lower_Layer,time)\n",
    "                # print(\"Objective value:\", temp_Lower_Layer.model.objVal)\n",
    "                objval = temp_Lower_Layer.model.objVal \n",
    "            else:\n",
    "                temp_Lower_Layer.model.computeIIS()\n",
    "                temp_Lower_Layer.model.write('iis.ilp')  # 保存不可行约束\n",
    "                # print(f\"{time}次，No optimal solution found.\")\n",
    "                self_update(Vehicles, G)\n",
    "                objval = basic_cost(Vehicles, orders_unmatched)\n",
    "                \n",
    "            \n",
    "            _, var_order = temp_Lower_Layer.get_decision()\n",
    "            update_var(temp_Lower_Layer, Vehicles, orders_unmatched)\n",
    "            vehicle_in_city = update_vehicle(Vehicles, battery_consume, battery_add, speed, G)\n",
    "            order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self_update(Vehicles, G)\n",
    "            # print(f\"{episode}轮，{time}次，{len(group[1])}辆车不在城市\")\n",
    "            order_canceled = order_canceled + update_order(orders_unmatched, time, speed)\n",
    "            objval = basic_cost(Vehicles, orders_unmatched)\n",
    "            # 利润（如果有）减去新增的取消订单\n",
    "            \n",
    "            invalid_time += 1\n",
    "        objval = objval - update_order(orders_unmatched, time, speed) * cancel_penalty\n",
    "        if episode != 0: \n",
    "            \n",
    "            # 防止梯度爆炸\n",
    "            grid_reward =  objval + reward\n",
    "            grid_rewards.append(grid_reward)\n",
    "            # print(grid_reward)\n",
    "            episode_reward += reward + objval\n",
    "        total_objval += objval\n",
    "\n",
    "        if episode == 0:\n",
    "            base_revenue.append(objval)\n",
    "            base_vehicle.append(copy.deepcopy(group[0]))\n",
    "            # base_vehicle_class.append(copy.deepcopy(Vehicles))\n",
    "            # base_order_class.append(copy.deepcopy(Total_order))\n",
    "            \n",
    "            base_city_node.append(copy.deepcopy(city_node))\n",
    "            \"\"\"\n",
    "            if episode == 1:\n",
    "                first_revnue.append(objval)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # if base_revenue[time] != objval:\n",
    "            #    print(\"base_revenue\",time, objval,base_revenue[time])\n",
    "            # if first_revnue[time] != objval:\n",
    "            #    print(\"first_revenue\",time, first_revnue[time], objval)\n",
    "            \"\"\" \n",
    "            if base_vehicle[time] != group[0]:\n",
    "                print(\"vehicle is different\", len(base_vehicle[time]), len(group[0]))\n",
    "            if base_city_node[time] != env.cities:\n",
    "                print(time, base_city_node[time],\"\\n\", env.cities)\n",
    "            \"\"\"\n",
    "            \n",
    "        # print(f\"{len(orders_unmatched)}订单未被匹配,{order_canceled}订单超时,总利润为{objval},强化学习利润为{reward}\")\n",
    "    end_time = tm.time()\n",
    "    execution_time = end_time - start_time\n",
    "    if episode != 0:\n",
    "        print(f\"执行时间: {execution_time} 秒,{invalid_time}次未求解，当前强化学习值为{episode_reward},利润为{total_objval}\")\n",
    "        # torch.save(agent.state_dict(), 'model_checkpoint.pth')\n",
    "    else:\n",
    "        print(f\"未加强化学习利润为{total_objval},{invalid_time}次未求解\")\n",
    "    # grid_rewards.append(0)\n",
    "    # save_path = f\"actor_critic_model{episode}.pth\"\n",
    "    # load_path = f\"actor_critic_model{episode}.pth\"\n",
    "    # agent.save_model(save_path)\n",
    "plt.plot(grid_rewards, label='Grid Reward Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Grid Reward')\n",
    "plt.title('Reward Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# print(find_duplicates_with_positions(ACTIONS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
